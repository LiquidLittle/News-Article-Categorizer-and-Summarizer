{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NY3Fhdib9BjR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, get_linear_schedule_with_warmup, Trainer , TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from rouge_score import rouge_scorer\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.nn.utils import clip_grad_norm_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4RZCGf29BjS",
        "outputId": "b7214bb9-7b79-4c0b-8997-244574c22465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gmib0oE9BjS",
        "outputId": "4bb31fb5-757e-4349-80da-a74a7b30f93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\chunl\\AppData\\Local\\Temp\\ipykernel_3084\\3004751869.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')\n",
        "\n",
        "tf.test.is_gpu_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MkGa4PVO9BjU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"merge_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Kx379VD69BjU",
        "outputId": "2429fd48-8274-467d-a574-3a67d1fac66f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>File_path</th>\n",
              "      <th>Articles</th>\n",
              "      <th>Summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>politics</td>\n",
              "      <td>Budget to set scene for election..Gordon Brown...</td>\n",
              "      <td>- Increase in the stamp duty threshold from £6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>politics</td>\n",
              "      <td>Army chiefs in regiments decision..Military ch...</td>\n",
              "      <td>\"They are very much not for the good and will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>politics</td>\n",
              "      <td>Howard denies split over ID cards..Michael How...</td>\n",
              "      <td>Michael Howard has denied his shadow cabinet w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>politics</td>\n",
              "      <td>Observers to monitor UK election..Ministers wi...</td>\n",
              "      <td>The report said individual registration should...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>politics</td>\n",
              "      <td>Kilroy names election seat target..Ex-chat sho...</td>\n",
              "      <td>UKIP's leader, Roger Knapman, has said he is g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5444</th>\n",
              "      <td>5444</td>\n",
              "      <td>accidents</td>\n",
              "      <td>HONG KONG  —   Hundreds of pilot whales that s...</td>\n",
              "      <td>more than 500 rescuers tried frantically to se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5445</th>\n",
              "      <td>5445</td>\n",
              "      <td>sports</td>\n",
              "      <td>NICE, France  —     Rivère accepts the complim...</td>\n",
              "      <td>Signing balotelli was not just a way to garner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5446</th>\n",
              "      <td>5446</td>\n",
              "      <td>business</td>\n",
              "      <td>FRANKFURT  —   Germans who never really warmed...</td>\n",
              "      <td>Although there was no evidence of that the bun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5447</th>\n",
              "      <td>5447</td>\n",
              "      <td>sports</td>\n",
              "      <td>Charles Oakley has strong feelings about compe...</td>\n",
              "      <td>He questioned why any n. b. a. free agent woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>5448</td>\n",
              "      <td>lifestyle</td>\n",
              "      <td>Hans Rosling, a Swedish doctor who transformed...</td>\n",
              "      <td>There are so many who think that death keeps c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5449 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  File_path  \\\n",
              "0              0   politics   \n",
              "1              1   politics   \n",
              "2              2   politics   \n",
              "3              3   politics   \n",
              "4              4   politics   \n",
              "...          ...        ...   \n",
              "5444        5444  accidents   \n",
              "5445        5445     sports   \n",
              "5446        5446   business   \n",
              "5447        5447     sports   \n",
              "5448        5448  lifestyle   \n",
              "\n",
              "                                               Articles  \\\n",
              "0     Budget to set scene for election..Gordon Brown...   \n",
              "1     Army chiefs in regiments decision..Military ch...   \n",
              "2     Howard denies split over ID cards..Michael How...   \n",
              "3     Observers to monitor UK election..Ministers wi...   \n",
              "4     Kilroy names election seat target..Ex-chat sho...   \n",
              "...                                                 ...   \n",
              "5444  HONG KONG  —   Hundreds of pilot whales that s...   \n",
              "5445  NICE, France  —     Rivère accepts the complim...   \n",
              "5446  FRANKFURT  —   Germans who never really warmed...   \n",
              "5447  Charles Oakley has strong feelings about compe...   \n",
              "5448  Hans Rosling, a Swedish doctor who transformed...   \n",
              "\n",
              "                                              Summaries  \n",
              "0     - Increase in the stamp duty threshold from £6...  \n",
              "1     \"They are very much not for the good and will ...  \n",
              "2     Michael Howard has denied his shadow cabinet w...  \n",
              "3     The report said individual registration should...  \n",
              "4     UKIP's leader, Roger Knapman, has said he is g...  \n",
              "...                                                 ...  \n",
              "5444  more than 500 rescuers tried frantically to se...  \n",
              "5445  Signing balotelli was not just a way to garner...  \n",
              "5446  Although there was no evidence of that the bun...  \n",
              "5447  He questioned why any n. b. a. free agent woul...  \n",
              "5448  There are so many who think that death keeps c...  \n",
              "\n",
              "[5449 rows x 4 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5-bOI-Un9BjU"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=\"Unnamed: 0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_rF15dWU9BjU",
        "outputId": "cec8a8f1-079b-4123-ff3e-1c2e61a5bacc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_path</th>\n",
              "      <th>Articles</th>\n",
              "      <th>Summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>politics</td>\n",
              "      <td>Budget to set scene for election..Gordon Brown...</td>\n",
              "      <td>- Increase in the stamp duty threshold from £6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>politics</td>\n",
              "      <td>Army chiefs in regiments decision..Military ch...</td>\n",
              "      <td>\"They are very much not for the good and will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>politics</td>\n",
              "      <td>Howard denies split over ID cards..Michael How...</td>\n",
              "      <td>Michael Howard has denied his shadow cabinet w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>politics</td>\n",
              "      <td>Observers to monitor UK election..Ministers wi...</td>\n",
              "      <td>The report said individual registration should...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>politics</td>\n",
              "      <td>Kilroy names election seat target..Ex-chat sho...</td>\n",
              "      <td>UKIP's leader, Roger Knapman, has said he is g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5444</th>\n",
              "      <td>accidents</td>\n",
              "      <td>HONG KONG  —   Hundreds of pilot whales that s...</td>\n",
              "      <td>more than 500 rescuers tried frantically to se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5445</th>\n",
              "      <td>sports</td>\n",
              "      <td>NICE, France  —     Rivère accepts the complim...</td>\n",
              "      <td>Signing balotelli was not just a way to garner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5446</th>\n",
              "      <td>business</td>\n",
              "      <td>FRANKFURT  —   Germans who never really warmed...</td>\n",
              "      <td>Although there was no evidence of that the bun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5447</th>\n",
              "      <td>sports</td>\n",
              "      <td>Charles Oakley has strong feelings about compe...</td>\n",
              "      <td>He questioned why any n. b. a. free agent woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>lifestyle</td>\n",
              "      <td>Hans Rosling, a Swedish doctor who transformed...</td>\n",
              "      <td>There are so many who think that death keeps c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5449 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      File_path                                           Articles  \\\n",
              "0      politics  Budget to set scene for election..Gordon Brown...   \n",
              "1      politics  Army chiefs in regiments decision..Military ch...   \n",
              "2      politics  Howard denies split over ID cards..Michael How...   \n",
              "3      politics  Observers to monitor UK election..Ministers wi...   \n",
              "4      politics  Kilroy names election seat target..Ex-chat sho...   \n",
              "...         ...                                                ...   \n",
              "5444  accidents  HONG KONG  —   Hundreds of pilot whales that s...   \n",
              "5445     sports  NICE, France  —     Rivère accepts the complim...   \n",
              "5446   business  FRANKFURT  —   Germans who never really warmed...   \n",
              "5447     sports  Charles Oakley has strong feelings about compe...   \n",
              "5448  lifestyle  Hans Rosling, a Swedish doctor who transformed...   \n",
              "\n",
              "                                              Summaries  \n",
              "0     - Increase in the stamp duty threshold from £6...  \n",
              "1     \"They are very much not for the good and will ...  \n",
              "2     Michael Howard has denied his shadow cabinet w...  \n",
              "3     The report said individual registration should...  \n",
              "4     UKIP's leader, Roger Knapman, has said he is g...  \n",
              "...                                                 ...  \n",
              "5444  more than 500 rescuers tried frantically to se...  \n",
              "5445  Signing balotelli was not just a way to garner...  \n",
              "5446  Although there was no evidence of that the bun...  \n",
              "5447  He questioned why any n. b. a. free agent woul...  \n",
              "5448  There are so many who think that death keeps c...  \n",
              "\n",
              "[5449 rows x 3 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9ONeMTJY9BjU"
      },
      "outputs": [],
      "source": [
        "filtered_df = df[df['File_path'] == 'entertainment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "x9cJHzSJ9BjV",
        "outputId": "d2712e19-3b25-4f9a-d556-8b962f3dc450"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_path</th>\n",
              "      <th>Articles</th>\n",
              "      <th>Summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1328</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Super Size Me wins writers' award..Super Size ...</td>\n",
              "      <td>Spurlock was given his award on the same day t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1329</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Mogul Wilson backing UK rap band..Tony Wilson,...</td>\n",
              "      <td>Tony Wilson, the music mogul who established t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1330</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Police praise 'courageous' Ozzy..Rock star Ozz...</td>\n",
              "      <td>\"I could have been badly injured or shot or an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1331</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Eastwood's Baby scoops top Oscars..Clint Eastw...</td>\n",
              "      <td>The boxing drama was named best picture and Ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Actor Scott is new Bond favourite..Bookmaker W...</td>\n",
              "      <td>Bookmaker William Hill has stopped taking bets...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5380</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>WASHINGTON  —   Senator Jeff Sessions was conf...</td>\n",
              "      <td>late tuesday republicans voted to formally sil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5400</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Was it just a year ago that Katie Holmes, Jenn...</td>\n",
              "      <td>aware that the payoff may be negligible many d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5405</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Mother Jones was named magazine of the year on...</td>\n",
              "      <td>also honored were pacific standard for feature...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Damien Chazelle, the writer and director of th...</td>\n",
              "      <td>what was it like to shoot there we were able t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5427</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>LOS ANGELES  —   Because he was told that   we...</td>\n",
              "      <td>a film about rural disenfranchisement and the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>925 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          File_path                                           Articles  \\\n",
              "1328  entertainment  Super Size Me wins writers' award..Super Size ...   \n",
              "1329  entertainment  Mogul Wilson backing UK rap band..Tony Wilson,...   \n",
              "1330  entertainment  Police praise 'courageous' Ozzy..Rock star Ozz...   \n",
              "1331  entertainment  Eastwood's Baby scoops top Oscars..Clint Eastw...   \n",
              "1332  entertainment  Actor Scott is new Bond favourite..Bookmaker W...   \n",
              "...             ...                                                ...   \n",
              "5380  entertainment  WASHINGTON  —   Senator Jeff Sessions was conf...   \n",
              "5400  entertainment  Was it just a year ago that Katie Holmes, Jenn...   \n",
              "5405  entertainment  Mother Jones was named magazine of the year on...   \n",
              "5408  entertainment  Damien Chazelle, the writer and director of th...   \n",
              "5427  entertainment  LOS ANGELES  —   Because he was told that   we...   \n",
              "\n",
              "                                              Summaries  \n",
              "1328  Spurlock was given his award on the same day t...  \n",
              "1329  Tony Wilson, the music mogul who established t...  \n",
              "1330  \"I could have been badly injured or shot or an...  \n",
              "1331  The boxing drama was named best picture and Ea...  \n",
              "1332  Bookmaker William Hill has stopped taking bets...  \n",
              "...                                                 ...  \n",
              "5380  late tuesday republicans voted to formally sil...  \n",
              "5400  aware that the payoff may be negligible many d...  \n",
              "5405  also honored were pacific standard for feature...  \n",
              "5408  what was it like to shoot there we were able t...  \n",
              "5427  a film about rural disenfranchisement and the ...  \n",
              "\n",
              "[925 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12r7GOZaZuui"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Im2Ftsy0ZoJV"
      },
      "outputs": [],
      "source": [
        "def remove_emojis_and_symbols(text):\n",
        "    # Remove emojis\n",
        "    text = re.sub(r'[\\U00010000-\\U0010ffff]', '', text)\n",
        "    # Remove non-alphanumeric symbols\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xvKV0yVZpSp",
        "outputId": "c3b34080-27c2-4b3c-f447-7c3494fac8ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chunl\\AppData\\Local\\Temp\\ipykernel_3084\\2494307040.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['Articles'] = filtered_df['Articles'].apply(remove_emojis_and_symbols)\n"
          ]
        }
      ],
      "source": [
        "filtered_df['Articles'] = filtered_df['Articles'].apply(remove_emojis_and_symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y6UOWfHZxMl",
        "outputId": "d179d0fe-3e43-4eac-aa09-ec7360e38754"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chunl\\AppData\\Local\\Temp\\ipykernel_3084\\969203157.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['Summaries'] = filtered_df['Summaries'].apply(remove_emojis_and_symbols)\n"
          ]
        }
      ],
      "source": [
        "filtered_df['Summaries'] = filtered_df['Summaries'].apply(remove_emojis_and_symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "w8-2xoTDZ9Sx",
        "outputId": "1a3b9bcb-fd34-405a-d298-af70047b94d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_path</th>\n",
              "      <th>Articles</th>\n",
              "      <th>Summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1328</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Super Size Me wins writers awardSuper Size Me ...</td>\n",
              "      <td>Spurlock was given his award on the same day t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1329</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Mogul Wilson backing UK rap bandTony Wilson th...</td>\n",
              "      <td>Tony Wilson the music mogul who established th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1330</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Police praise courageous OzzyRock star Ozzy Os...</td>\n",
              "      <td>I could have been badly injured or shot or any...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1331</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Eastwoods Baby scoops top OscarsClint Eastwood...</td>\n",
              "      <td>The boxing drama was named best picture and Ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Actor Scott is new Bond favouriteBookmaker Wil...</td>\n",
              "      <td>Bookmaker William Hill has stopped taking bets...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5380</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>WASHINGTON     Senator Jeff Sessions was confi...</td>\n",
              "      <td>late tuesday republicans voted to formally sil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5400</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Was it just a year ago that Katie Holmes Jenni...</td>\n",
              "      <td>aware that the payoff may be negligible many d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5405</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Mother Jones was named magazine of the year on...</td>\n",
              "      <td>also honored were pacific standard for feature...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>Damien Chazelle the writer and director of the...</td>\n",
              "      <td>what was it like to shoot there we were able t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5427</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>LOS ANGELES     Because he was told that   wer...</td>\n",
              "      <td>a film about rural disenfranchisement and the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>925 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          File_path                                           Articles  \\\n",
              "1328  entertainment  Super Size Me wins writers awardSuper Size Me ...   \n",
              "1329  entertainment  Mogul Wilson backing UK rap bandTony Wilson th...   \n",
              "1330  entertainment  Police praise courageous OzzyRock star Ozzy Os...   \n",
              "1331  entertainment  Eastwoods Baby scoops top OscarsClint Eastwood...   \n",
              "1332  entertainment  Actor Scott is new Bond favouriteBookmaker Wil...   \n",
              "...             ...                                                ...   \n",
              "5380  entertainment  WASHINGTON     Senator Jeff Sessions was confi...   \n",
              "5400  entertainment  Was it just a year ago that Katie Holmes Jenni...   \n",
              "5405  entertainment  Mother Jones was named magazine of the year on...   \n",
              "5408  entertainment  Damien Chazelle the writer and director of the...   \n",
              "5427  entertainment  LOS ANGELES     Because he was told that   wer...   \n",
              "\n",
              "                                              Summaries  \n",
              "1328  Spurlock was given his award on the same day t...  \n",
              "1329  Tony Wilson the music mogul who established th...  \n",
              "1330  I could have been badly injured or shot or any...  \n",
              "1331  The boxing drama was named best picture and Ea...  \n",
              "1332  Bookmaker William Hill has stopped taking bets...  \n",
              "...                                                 ...  \n",
              "5380  late tuesday republicans voted to formally sil...  \n",
              "5400  aware that the payoff may be negligible many d...  \n",
              "5405  also honored were pacific standard for feature...  \n",
              "5408  what was it like to shoot there we were able t...  \n",
              "5427  a film about rural disenfranchisement and the ...  \n",
              "\n",
              "[925 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myio2ZDOPO0h",
        "outputId": "61a0c4e5-bb3b-431d-f520-c3eaafb3adfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=16fd3ff078074db0ab0d13fba77bc51b36ea21bfcbf92b5ea15e958d71851fdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "! pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dRrKkBHd9BjV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "ad9fcfa0729e488bacba856323929d39",
            "8477577de62f4c6c828a8c394867b119",
            "c0c119eed0004c1789634e730a2f99d5",
            "2456eaf7fb974b8088460839ff104c0e",
            "75be190f9fa44cd3b8e26c21dd30efa2",
            "3aeafe3ba1914caca3ad151f34640579",
            "f7ed2de5ee0842e8b4859433ee131ba3",
            "7c6ff626069f48ca9ff6f78e93f609a6",
            "0a7f6e94dc9849fdb93000eb118d0dec",
            "066d6d7d10b54583a09cf7c08a874581",
            "d2be5caa361d4ccca12b105fe3388250",
            "a332f2e780de4b1385d97828de8cd28c",
            "7f2dbc10d6c5436494053d04e690c4f4",
            "40362fbd63bd40fc974d134581f82b3b",
            "3b3c4f98d34946e4b9027be887363bc1",
            "20fcad0c61e14ca487ad3238a60f07c9",
            "3026edeb81e944768aa8ab39e27add98",
            "b6c8dfcf93844a75aeb248db1d6cf10e",
            "9233e4395062499985570de3f2252afc",
            "7399d9e108dc493db406a113f58d9582",
            "c1be25eb162442e1b13ea1355169d3f1",
            "15685bf25d0847e38e24e8156098a35a",
            "eedee2bbb01b4461814d784ee65baa05",
            "18ec1f06b06b4030afdab4374dd6b669",
            "8b930e19be7748cd84d2a8bb2e59ce0c",
            "b64a383e0ffd40059caf47dd4baf09ef",
            "a399fb03b3a04061bdd950dc80e5a6da",
            "5ea76bd4fd37485d9b7af68e433b7ea7",
            "3bb4137ef6fd4ae3b97d495a0ab33fa6",
            "1c1f5ffb197c4c6c892987fea34e9bba",
            "c03be050658e4b5d88d997289682328f",
            "2b0369f1b7574da28d3505b0f1b620cf",
            "88b8bc860c6b4e34bdc2794370cedc16",
            "48cd6da2bbdf43549648c8989dadae51",
            "8586cc1d2c3c4207a5ef78a64d3757c9",
            "863dd204bb0d4d8095dc157110efcee7",
            "fa8f13e901b14ed6aad026b70d6e6c49",
            "19b34c333da949debd9aa987bdedc50d",
            "fb84d598a07844ebbf703bde8f81aabb",
            "8e73ccb4ad314ba884adbf21df95a491",
            "47c8f5699c7a4fa78a8facb75c9dfadc",
            "4fce92fdfbc942deb64fddf08d4c11c5",
            "1222626362114654838a3c800d5bf9e7",
            "a32737b2f01d45e8b4a02908abe8575a"
          ]
        },
        "id": "o_-sZXe59BjV",
        "outputId": "cd1c1044-eadc-48ee-be4b-831468f615c8"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Tokenize and preprocess the text data\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "max_length = 1024  # Maximum sequence length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQL-oB4_9BjV",
        "outputId": "bcb487fa-4936-41de-b195-b560d270a6d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chunl\\AppData\\Local\\Temp\\ipykernel_3084\\827673237.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['TokenizedText'] = filtered_df['Articles'].apply(tokenize_text)\n",
            "C:\\Users\\chunl\\AppData\\Local\\Temp\\ipykernel_3084\\827673237.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['TokenizedSummary'] = filtered_df['Summaries'].apply(tokenize_summary)\n"
          ]
        }
      ],
      "source": [
        "def tokenize_text(text):\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True, padding='max_length', return_attention_mask=True)\n",
        "    return inputs.to(device)  # Move the tokenized inputs to the GPU\n",
        "\n",
        "def tokenize_summary(text):\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=300, truncation=True, padding='max_length', return_attention_mask=True)\n",
        "    return inputs.to(device)  # Move the tokenized summaries to the GPU\n",
        "\n",
        "\n",
        "filtered_df['TokenizedText'] = filtered_df['Articles'].apply(tokenize_text)\n",
        "filtered_df['TokenizedSummary'] = filtered_df['Summaries'].apply(tokenize_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "agbV0TlA9BjV"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(filtered_df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vA7x277Z9BjW"
      },
      "outputs": [],
      "source": [
        "X_train = torch.stack([seq.squeeze() for seq in train_df['TokenizedText']])\n",
        "Y_train = torch.stack([seq.squeeze() for seq in train_df['TokenizedSummary']])\n",
        "X_test = torch.stack([seq.squeeze() for seq in test_df['TokenizedText']])\n",
        "Y_test = torch.stack([seq.squeeze() for seq in test_df['TokenizedSummary']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1-_MLgjW9BjW"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_dataset = TensorDataset(X_test, Y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [f\"summarize: {article}\" for article in examples['Articles']]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding='max_length'\n",
        "    )\n",
        " \n",
        "    # Set up the tokenizer for targets\n",
        "    targets = [summary for summary in examples['Summaries']]\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            targets,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding='max_length'\n",
        "        )\n",
        " \n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "articles = DatasetDict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train, data_test = train_test_split(df, test_size=0.10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = Dataset.from_pandas(data_train, preserve_index=False)\n",
        "test_ds = Dataset.from_pandas(data_test, preserve_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "articles['train'] = train_ds\n",
        "articles['test'] = test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train = articles['train']\n",
        "dataset_valid = articles['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=4):   0%|          | 0/4904 [00:01<?, ? examples/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py\", line 614, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"c:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 3470, in _map_single\n    batch = apply_function_on_filtered_inputs(\n  File \"c:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 3349, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n  File \"C:\\Users\\chunl\\AppData\\Local\\Temp\\ipykernel_3084\\3297978533.py\", line 3, in preprocess_function\nNameError: name 'tokenizer' is not defined\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_train \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 592\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    593\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    555\u001b[0m }\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3185\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3179\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3181\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3182\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3183\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3184\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3185\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[0;32m   3186\u001b[0m         pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[0;32m   3187\u001b[0m     ):\n\u001b[0;32m   3188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3189\u001b[0m             shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py:654\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[1;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[1;32m--> 654\u001b[0m         [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py:654\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[1;32m--> 654\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\multiprocess\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "tokenized_train = dataset_train.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c8415c323544486b979fb09ee707a2cc",
            "a92d3b0cd6d04dafb6b65c31161086a1",
            "30b37d3baad64a369ea196e8dab97e78",
            "fa40d9863b34461ab4ad7486a3a5caf3",
            "9da5ad56ea184cc88485ad79e6f33920",
            "f1a5a40069a54f1a8575ba9f133ef5ab",
            "772a3268234e4ead97c020c9daf3b893",
            "ab0550ed999444639bbf99eab300ed75",
            "2335e907a4454f1b84b9d49936409c9a",
            "8a711996a086461eb137f6536d2bba8a",
            "1b6160dacfbd49f28b51ddfec75a0dc0"
          ]
        },
        "id": "HKQHiKZ09BjW",
        "outputId": "52c53fd6-6214-408a-c724-8f86f48d4f49"
      },
      "outputs": [],
      "source": [
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MY6lglOe9BjW"
      },
      "outputs": [],
      "source": [
        "# Create a GradScaler for mixed-precision training\n",
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r39kzdk79BjW",
        "outputId": "ec4a9145-9436-4601-a49d-9398f83c67ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 768, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)  # Move the model to the GPU\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 100%|██████████| 6.27k/6.27k [00:00<00:00, 6.28MB/s]\n"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred.predictions[0], eval_pred.label_ids\n",
        " \n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        " \n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True,\n",
        "        rouge_types=[\n",
        "            'rouge1',\n",
        "            'rouge2',\n",
        "            'rougeL'\n",
        "        ]\n",
        "    )\n",
        " \n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        " \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    \"\"\"\n",
        "    Original Trainer may have a memory leak.\n",
        "    This is a workaround to avoid storing too many tensors that are not needed.\n",
        "    \"\"\"\n",
        "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
        "    return pred_ids, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"results_bart\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"results_bart\",\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=200,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=2,\n",
        "    report_to='tensorboard',\n",
        "    learning_rate=0.0003,\n",
        "    dataloader_num_workers=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_valid,\n",
        "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=50, num_training_steps=len(train_dataloader) * 10)  # Add learning rate scheduler\n",
        "early_stopping_rounds = 2\n",
        "best_rouge_score = -1\n",
        "current_round = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4Cx2vC7h9BjW"
      },
      "outputs": [],
      "source": [
        "# Define gradient accumulation steps\n",
        "accumulation_steps = 20  # You can adjust this number\n",
        "\n",
        "def train(model, dataloader, optimizer, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, batch in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
        "        inputs = batch[0].to(device)  # Move the input batch to the GPU\n",
        "        attention_mask = (inputs != 0).float().to(device)  # Create attention mask\n",
        "        targets = batch[1].to(device)  # Move the target batch to the GPU\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(input_ids=inputs, attention_mask=attention_mask, decoder_input_ids=targets, labels=targets)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        # Perform gradient accumulation\n",
        "        loss = loss / accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            # Update gradients and optimizer once every accumulation_steps\n",
        "            clip_grad_norm_(model.parameters(), max_norm=1.0)  # Optional gradient clipping\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "ikRfCkg99BjX",
        "outputId": "4797d9f1-5f43-4db3-cc5c-0a5fbade0c46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 185/185 [06:16<00:00,  2.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 0.7028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 185/185 [06:28<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Train Loss: 0.7044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 185/185 [06:28<00:00,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Train Loss: 0.7034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "    train_loss = train(model, train_dataloader, optimizer, scheduler)\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "1Z-Gc3dWRgI4"
      },
      "outputs": [],
      "source": [
        "def evaluate1(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    test_articles = []\n",
        "    actual_summaries = []\n",
        "    predicted_summaries = []\n",
        "    rouge1_precision_scores = []\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1'])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating Test\"):\n",
        "            inputs = batch[0].to(device)\n",
        "            attention_mask = (inputs != 0).float().to(device)\n",
        "            targets = batch[1].to(device)\n",
        "            outputs = model.generate(input_ids=inputs, attention_mask=attention_mask, max_length=512, num_beams=30, length_penalty=3.0, early_stopping=True)\n",
        "\n",
        "            for output, target, input_text in zip(outputs, targets, inputs):\n",
        "                # Calculate ROUGE-1 precision for each sample\n",
        "                output_text = tokenizer.decode(output, skip_special_tokens=True)\n",
        "                target_text = tokenizer.decode(target, skip_special_tokens=True)\n",
        "                rouge_scores = scorer.score(output_text, target_text)\n",
        "                rouge1_precision_scores.append(rouge_scores['rouge1'].precision)\n",
        "\n",
        "                # Append tokenized text, actual summaries, and predicted summaries\n",
        "                test_articles.append(tokenizer.decode(input_text, skip_special_tokens=True))\n",
        "                actual_summaries.append(target_text)\n",
        "                predicted_summaries.append(output_text)\n",
        "\n",
        "    return test_articles, actual_summaries, predicted_summaries, rouge1_precision_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Quo3RSrhRhC9"
      },
      "outputs": [],
      "source": [
        "def evaluate2(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    test_articles = []\n",
        "    actual_summaries = []\n",
        "    predicted_summaries = []\n",
        "    rouge2_precision_scores = []\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge2'])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating Test\"):\n",
        "            inputs = batch[0].to(device)\n",
        "            attention_mask = (inputs != 0).float().to(device)\n",
        "            targets = batch[1].to(device)\n",
        "            outputs = model.generate(input_ids=inputs, attention_mask=attention_mask, max_length=512, num_beams=30, length_penalty=3.0, early_stopping=True)\n",
        "\n",
        "            for output, target, input_text in zip(outputs, targets, inputs):\n",
        "                # Calculate ROUGE-2 precision for each sample\n",
        "                output_text = tokenizer.decode(output, skip_special_tokens=True)\n",
        "                target_text = tokenizer.decode(target, skip_special_tokens=True)\n",
        "                rouge_scores = scorer.score(output_text, target_text)\n",
        "                rouge2_precision_scores.append(rouge_scores['rouge2'].precision)\n",
        "\n",
        "                # Append tokenized text, actual summaries, and predicted summaries\n",
        "                test_articles.append(tokenizer.decode(input_text, skip_special_tokens=True))\n",
        "                actual_summaries.append(target_text)\n",
        "                predicted_summaries.append(output_text)\n",
        "\n",
        "    return test_articles, actual_summaries, predicted_summaries, rouge2_precision_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uGWDncu19BjX",
        "outputId": "d26f0356-fb50-41a1-c970-593adb529fb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Test:   0%|          | 0/47 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 18.01 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[85], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_articles, actual_summaries, predicted_summaries, rouge1_precision_scores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a dictionary with the extracted data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArticle\u001b[39m\u001b[38;5;124m'\u001b[39m: test_articles,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Summary\u001b[39m\u001b[38;5;124m'\u001b[39m: actual_summaries,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Summary\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_summaries,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROUGE-1 Precision\u001b[39m\u001b[38;5;124m'\u001b[39m: rouge1_precision_scores,\n\u001b[0;32m     10\u001b[0m }\n",
            "Cell \u001b[1;32mIn[83], line 16\u001b[0m, in \u001b[0;36mevaluate1\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m     14\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m (inputs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m targets \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output, target, input_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outputs, targets, inputs):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Calculate ROUGE-1 precision for each sample\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     output_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1558\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1552\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1553\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   1554\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1555\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1556\u001b[0m     )\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_search(\n\u001b[0;32m   1559\u001b[0m         input_ids,\n\u001b[0;32m   1560\u001b[0m         beam_scorer,\n\u001b[0;32m   1561\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1562\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1563\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[0;32m   1564\u001b[0m         eos_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m   1565\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_scores,\n\u001b[0;32m   1566\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1567\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1568\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1569\u001b[0m     )\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1573\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:2942\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2938\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   2940\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m-> 2942\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2943\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2944\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2945\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2946\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2947\u001b[0m )\n\u001b[0;32m   2949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2950\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1731\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1727\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1728\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1729\u001b[0m         )\n\u001b[1;32m-> 1731\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1747\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1750\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1617\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1610\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1611\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1612\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1613\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1614\u001b[0m     )\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1617\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1470\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1457\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1458\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1459\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1467\u001b[0m         use_cache,\n\u001b[0;32m   1468\u001b[0m     )\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1470\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   1478\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1483\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:779\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m    778\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 779\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    787\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    788\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:563\u001b[0m, in \u001b[0;36mBartSdpaAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    560\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_cross_attention:\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;66;03m# cross_attentions\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[0;32m    564\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(key_value_states), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;66;03m# reuse k, v, self_attention\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\chunl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 18.01 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_articles, actual_summaries, predicted_summaries, rouge1_precision_scores = evaluate1(model, test_dataloader)\n",
        "\n",
        "# Create a dictionary with the extracted data\n",
        "data = {\n",
        "    'Article': test_articles,\n",
        "    'Actual Summary': actual_summaries,\n",
        "    'Predicted Summary': predicted_summaries,\n",
        "    'ROUGE-1 Precision': rouge1_precision_scores,\n",
        "}\n",
        "\n",
        "# Create a Pandas DataFrame from the dictionary\n",
        "results_rouge1_df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Display the DataFrame\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "results_rouge1_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57OeCQ__ThoM"
      },
      "outputs": [],
      "source": [
        "results_rouge1_df.to_excel('results_rouge11.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EQMFadOESGtz",
        "outputId": "c3ac7ae9-fbb2-4910-8d21-8bb535772036"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Test: 100%|██████████| 12/12 [4:06:39<00:00, 1233.31s/it] \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "      <th>Actual Summary</th>\n",
              "      <th>Predicted Summary</th>\n",
              "      <th>ROUGE-2 Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Belle named best Scottish bandBelle  Sebastian have been named the best Scottish band of all time after a three monthlong public pollThe group beat Travis and Idlewild into second and third place respectively Franz Ferdinand who recently picked up five Brit Award nominations ended up in 15th place while the Eurythmics wound up at a lowly 38 Other Scottish acts such as the Mull Historical Society who also featured in the top 50 performed at a party in Glasgow where the result was announced Scottishbased band Snow Patrol who finished 14th in the vote and have been nominated for a pair of Brit Awards were among the performers who covered wellknown Scottish pop songs at the party on Wednesday nightIndie stalwarts Belle  Sebastian have enjoyed a chart career stretching back to 1997 They were the surprise winners of the Brit Award for best breakthrough act two years later Scottish bands from earlier musical eras also made it into the final list including 1970s tartan boy band the Bay City Rollers and goth favourites the Jesus and Mary ChainScottish magazine The List recently compiled a list of the top 50 Scottish bands of all time but left the final decision to the public The magazines music editor Mark Robertson said The idea behind the project was simple  to rediscover the very best of Scottish music from the finest musical talent spanning from the age of 70s rock through to 80s pop right up to todays international stars Everyone has strong opinions about this and we wanted to open it up to the public to decide he added BBC Radio Scotland presenter Vic Galloway who has been involved in the project said it had been great fun to look back at Scotlands musical heritage and take note of upandcoming Scottish acts</td>\n",
              "      <td>Belle  Sebastian have been named the best Scottish band of all time after a three monthlong public pollScottish magazine The List recently compiled a list of the top 50 Scottish bands of all time but left the final decision to the publicScottish bands from earlier musical eras also made it into the final list including 1970s tartan boy band the Bay City Rollers and goth favourites the Jesus and Mary ChainScottishbased band Snow Patrol who finished 14th in the vote and have been nominated for a pair of Brit Awards were among the performers who covered wellknown Scottish pop songs at the party on Wednesday nightBBC Radio Scotland presenter Vic Galloway who has been involved in the project said it had been great fun to look back at Scotlands musical heritage and take note of upandcoming Scottish acts</td>\n",
              "      <td>If you recently picked up five Brit Award nominations ended up in 15th place while the Eurythmics on a high on a party in Glasgow where the result was announced (Belle named best Scottish bandBelle  Sebastian have been named the best “Best Scottish band of all time after a three monthlong public pollThe group beat Travis and Idlewild into second and third place on Wednesday nightHonie on the highest highest highest awarded highest highest on high highest ground on the ground on Wednesday Night Franz Ferdinand who recently picked a high high “You’ki’’s “If” or “E‘›”“If you’st on the top 50 performed</td>\n",
              "      <td>0.131387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>She had us at the hat toss Mary Richards was a modest Midwestern girl to be sure but she had style and she had spunk as her new boss Lou Grant pointed out the day she walked into the   newsroom in her white   boots a pleated miniskirt and those impeccable manners When she threw her tam in the air during the shows opening credits we knew she was thrilled to be single and on her own in the big city of Minneapolis But as the series unfolded and we watched Mary Tyler Moores most famous character dress for work in the uniform of career women all over the country     the clingy knit dresses the matching   pantsuits the Evan Picone separates     she showed us her heart was in that newsroom Ms Moore died on Wednesday in Greenwich Conn  Read Mary Tyler Moores obituary  5 great episodes to stream  There was a cultural sweet spot in the 1970s as the old social mores unraveled along with the sweater girl and women flexed new muscles as working women divorced women women commited to the single life newly conscious women     to use the parlance of the   feminist playbook     and fashion reflected the fluidity of that time As women were reinventing themselves fashion helped them along Clothing even in the office was colorful and personal those jersey dresses and knit pantsuits moved with the body And they were womanly Marys inherent authority     that moral compass     was never compromised by the fact that she dressed in the basic idiom of her gender By the next decade that freedom would be snuffed out and working girls would ape the rigid suits of their male competitors but thats another story And like all working women she wore the same outfit more than once and so her wardrobe became as familiar as our own Her predecessor Ann Marie of That Girl played by Marlo Thomas was our first television singleton but paired from the   with her boyfriend Donald She made her debut in the 1960s a period that for women on the small screen was still the dark ages Mary Richards had boyfriends but they were ancillary to her real life which played out at work Looking back at both shows the clothing displayed the maturation or the evolution of the female television avatar Ann Marie dressed almost like a child in the shows early episodes in the cartoonish youthquake fashions of Mary Quant and others which Ms Thomas brought with her from London The bunny hat notwithstanding Mary Richards looked like a    The Mary Tyler Moore Show always embraced the real world and as it unfurled that world grew a little darker as did Mary Richards clothes In the final episode the newsroom is under assault Ratings are low and Mary and the gang are fired But Mary is armored Clad in a navy blue jumpsuit like a fighter pilot her hair cropped to her shoulders she is strong enough to say goodbye and turn out those lights</td>\n",
              "      <td>But as the series unfolded and we watched Mary Tyler Moores most famous character dress for work in the uniform of career women all over the country  the clingy knit dresses the matching pantsuits the Evan Picone separates  she showed us her heart was in that newsroom\\n\\nMs Moore died on Wednesday in Greenwich Conn There was a cultural sweet spot in the 1970s as the old social mores unraveled and women flexed new muscles as working women divorced women women commited to the single life newly conscious women  to use the parlance of the feminist playbook  and fashion reflected the fluidity of that time\\n\\nMary Richards had boyfriends but they were ancillary to her real life which played out at work\\n\\nAnn Marie dressed almost like a child in the shows early episodes in the cartoonish youthquake fashions of Mary Quant and others which Ms Thomas brought with her from London\\n\\nThe Mary Tyler Moore Show always embraced the real world and as it unfurled that world grew a little darker as did Mary Richards clothes</td>\n",
              "      <td>She’s wearing a white   boots a pleated miniskirt and those impeccable manners When she threw her tam in the air during the shows opening credits we knew she was thrilled to be single and on her own in the big city of Minneapolis But as the series unfolded and we watched Mary Tyler Moores most famous Midwestern girl to be sure but she had style and she had spunk as her new boss Lou Grant pointed out the day she walked into the    newsroom in her white iced   black   white  bikki   bkk on top of the highest ground on the ground with your highest pins on your current Mau Mau Maui wears on Wednesday in Greenwich Conn</td>\n",
              "      <td>0.113636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Celebrities get to stay in jungleAll four contestants still remain in Im A Celebrity  Get Me Out Of Here as no evictions were made on the television show on SaturdayContestants Paul Burrell Joe Pasquale Janet StreetPorter and Fran Cosgrave were told by hosts Ant and Dec Natalie Appletons decision to quit the show last Monday had given them all a stay of execution the group were told Model Sophie Anderton was the last person to be voted off the ITV1 show set in the Australian jungle The four remaining stars will do a joint Bushtucker Trial on SundayFormer All Saints singer Natalie Appleton31 walked out of the show after learning she would face a fifth socalled Bushtucker Trial The celebrities are chosen by the viewers to pass trials in order to win food for the rest of the camp Appleton had endured a torrid time during the programme including a wellpublicised row with Sophie Anderton And on 26 November singer Brian Harvey quit as a contestant after he had a blazing row with Janet StreetPorter</td>\n",
              "      <td>Former All Saints singer Natalie Appleton31 walked out of the show after learning she would face a fifth socalled Bushtucker TrialAll four contestants still remain in Im A Celebrity  Get Me Out Of Here as no evictions were made on the television show on SaturdayAnd on 26 November singer Brian Harvey quit as a contestant after he had a blazing row with Janet StreetPorterModel Sophie Anderton was the last person to be voted off the ITV1 show set in the Australian jungle</td>\n",
              "      <td>”“’›› on your Ter on “If’ on a Ter Ter on on Mau Mau Mau on on Ter Ter in Im A Celebrity  Get Me Out Of Here as no on the on the television show on Saturday on SaturdayContestants Paul Burrell Joe Pasquale Janet StreetPorter and Fran Cosgrave were told by hosts Ant and Dec Natalie Appletines by “On’ Ter” on the show last Monday had given them all a stay of execution the group were told Model Sophie Anderton was the last person to be voted off the ITV1 show on the Ter Terrace on the Australian Terrace Race on SundayFormer All Saints singer Natalie Appleton31</td>\n",
              "      <td>0.395062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A few hours after her fathers news conference on Wednesday at Trump Tower Ivanka Trump posted a notice on her personal Facebook page officially announcing that she was taking a formal leave of absence from all management and operative responsibilities at her fashion brand and that she would be stepping down from her role at the Trump Organization She would she wrote be spending the next few months concentrating on settling her children into their new lives in Washington and exploring how she could determine the most impactful and appropriate ways for me to serve our country  This follows earlier decisions to separate her personal social media accounts from those of her brand Yet in one meaningful area Ms Trump and her brand are harder to divide That is her wardrobe After all the same day she announced she was separating Ivanka Trump the person from Ivanka Trump the brand The Daily Mail announced she had worn an Ivanka Trump coat to her fathers news conference Then it offered a    box and link In case you know anyone wanted to buy the garment That turned out not to be true     according to a spokesman for Ms Trump the coat was by Joseph Altuzarra     but the confusion around woman and product made for some uncomfortable optics and it raises the question What does it mean to separate individual from company where fashion is concerned On the one hand theres something ridiculous about suggesting that Ms Trump not wear whatever clothes are in her closet and as the founder of a fashion brand that bears her name presumably part of her job has been to promote said brand by wearing it     to in effect demonstrate her belief in her own products So she probably has a lot of such products within reach And its not her fault if some media outlet chooses to point out that she looks good and tells people how they too can look good On the other hand her brand is clearly built on her image Not just her name but her face and what she represents Its selling the promise that women who wear her clothes can get a piece of her gold dust     and now that this gold dust is visible in the corridors and news conferences of power that is only going to be more true Every time she is pictured in an Ivanka Trump outfit it is bound to give a boost to the Ivanka Trump brand Whether or not they are technically linked Its unclear whether Ms Trump would benefit from that financially as specifics about her monetary relationship with her brand were not included in her statement But even if she is selling her part of the company for a prominent member of the first family to be seen to be endorsing a brand with her own name on it is a complicated proposition And an endorsement is exactly what an appearance in an item of clothing has become This is a time like it or not of obsession with the wardrobe selections of anyone in the public eye especially women in the public eye their clothes are more interesting than mens after all And though she has repeatedly said that she will not take a formal role in the new administration Ms Trump is emerging as the female face of her fathers inner circle Simply consider the news conference where she was the only woman from the immediate family in attendance Theres a reason The Daily Mail did not get into the specifics of what her brothers wore She is smart enough to know that any time she steps out of her door someone is going to try to snap a picture and parse her clothes You can argue that Ms Trump is not an elected official and thus to demand that she recuse herself from all products associated with her name is unfair punishment You could say that if she wears for example an Alexander McQueen dress as she did on election night she is giving that brand a boost so why shouldnt she do the same for her own brand You can point out that there is precedent because she wore her own line numerous times during the campaign including to introduce her father at the Republican National Convention     but then the latter choice was not without controversy In part the resulting brouhaha was of course because her brand then promoted that appearance with its own get the look link as it famously did without her knowledge when she wore her   bracelet during her familys appearance on 60 Minutes  Presumably that wont happen any more But brands need personalities to succeed at whatever price point and those personalities derive most easily from well a person A scenario in which Ivanka Trump the brand removes Ms Trump utterly from its identity is hard to imagine Though to be fair the brands website is adorned with images and line drawings of many different kinds of women and not with Ms Trump so it may be possible Either way this is another illustration of the multiple complicated issues that are going to arise with a member of the first family who also had designs on being a fashion brand Theres really no playbook for this as the Ivanka team     figuring it out as it goes along     is quick to remind In which case the clothes question should be the next piece of the puzzle to be solved</td>\n",
              "      <td>A few hours after her fathers news conference on Wednesday at Trump Tower Ivanka Trump posted a notice on her personal Facebook page officially announcing that she was taking a formal leave of absence from all management and operative responsibilities at her fashion brand and that she would be stepping down from her role at the Trump Organization\\n\\nAfter all the same day she announced she was separating Ivanka Trump the person from Ivanka Trump the brand The Daily Mail announced she had worn an Ivanka Trump coat to her fathers news conference\\n\\nOn the one hand theres something ridiculous about suggesting that Ms Trump not wear whatever clothes are in her closet and as the founder of a fashion brand that bears her name presumably part of her job has been to promote said brand by wearing it  to in effect demonstrate her belief in her own products\\n\\nEvery time she is pictured in an Ivanka Trump outfit it is bound to give a boost to the Ivanka Trump brand\\n\\nA scenario in which Ivanka Trump the brand removes Ms Trump utterly from its identity is hard to imagine</td>\n",
              "      <td>A few hours after her father news conference on Wednesday at Trump Tower Ivanka Trump posted a notice on her personal Facebook page officially announcing that she was taking a formal leave of absence from all management and operative responsibilities at her fashion brand and that she would be stepping down from her role at the Trump Organization She would she wrote be spending the next few months concentrating on settling her children into their new lives in Washington and exploring how she could determine the most impactful and appropriate ways for me to serve our country  This follows earlier decisions to separate her personal social media accounts from those of her brand Yet in one meaningful area Ms Trump and her brand are harder to divide That is her wardrobe After all the same day she announced she was separating Ivanka Trump the person</td>\n",
              "      <td>0.370370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oscars race enters final furlongThe race for the Oscars entered its final stages as the deadline for voters to choose their winners passedThe 5808 Academy voters had until Tuesday afternoon to return their ballots  any late submissions will not be included in the count The next five days will be spent counting the voting forms and preparing the winners envelopes Best actor nominee Leonardo DiCaprio is to present a statuette for the first time at the LA ceremony on SundayThe 30yearold actor who is nominated for playing Howard Hughes in The Aviator will join other hopefuls such as costar Cate Blanchett Natalie Portman and Kate Winslet as Oscar presenters The only people who will know the Oscar winners before they are revealed at the ceremony will be the auditors who are in charge of looking after the ballot countAfter collating the results they are responsible for sealing the results in the famous golden envelopes which will be revealed by a host of celebrity presenters at the ceremony Former Academy Award winners Gwyneth Paltrow Dustin Hoffman and Halle Berry will also present prizes The event at the Kodak Theatre will be attended by 3300 people including some of the bestknown names in film and organisers say they expect it will be watched on television by one billion people around the world One current concern is the torrential rain which has lashed Los Angeles for the past week flooding suburbs and causing mudslides It is hoped the forecast for Sunday for cool weather but no rain will prove accurate The last time it rained on Oscars night was in the midtolate 1980s said Oscars communications director John Pavlik We have had rain up until the day before the show many times but for some reason the Oscar gods always shine on Sunday and we hope they will do so again this year he added</td>\n",
              "      <td>The only people who will know the Oscar winners before they are revealed at the ceremony will be the auditors who are in charge of looking after the ballot countWe have had rain up until the day before the show many times but for some reason the Oscar gods always shine on Sunday and we hope they will do so again this year he addedBest actor nominee Leonardo DiCaprio is to present a statuette for the first time at the LA ceremony on SundayThe race for the Oscars entered its final stages as the deadline for voters to choose their winners passedIt is hoped the forecast for Sunday for cool weather but no rain will prove accurateThe 5808 Academy voters had until Tuesday afternoon to return their ballots  any late submissions will not be included in the count</td>\n",
              "      <td>The next five days will be spent counting the voting forms and preparing the winners envelopes Best actor nominee Leonardo DiCaprio is to present a statuette for the first time at the LA ceremony on SundayThe 30yearold actor who is nominated for playing Howard Hughes in The Aviator will join other hopefuls such as costar Cate Blanche on the race for the Oscars entered its final stages as the deadline for voters to choose their winners onThe 5808 Academy voters had until Tuesday afternoon to return their ballots  any late submissions will not be included in the count The next 5 days will are spent watching the voting “If you’re a current aimon’s you are responsible for watching the results in</td>\n",
              "      <td>0.401460</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Article  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Belle named best Scottish bandBelle  Sebastian have been named the best Scottish band of all time after a three monthlong public pollThe group beat Travis and Idlewild into second and third place respectively Franz Ferdinand who recently picked up five Brit Award nominations ended up in 15th place while the Eurythmics wound up at a lowly 38 Other Scottish acts such as the Mull Historical Society who also featured in the top 50 performed at a party in Glasgow where the result was announced Scottishbased band Snow Patrol who finished 14th in the vote and have been nominated for a pair of Brit Awards were among the performers who covered wellknown Scottish pop songs at the party on Wednesday nightIndie stalwarts Belle  Sebastian have enjoyed a chart career stretching back to 1997 They were the surprise winners of the Brit Award for best breakthrough act two years later Scottish bands from earlier musical eras also made it into the final list including 1970s tartan boy band the Bay City Rollers and goth favourites the Jesus and Mary ChainScottish magazine The List recently compiled a list of the top 50 Scottish bands of all time but left the final decision to the public The magazines music editor Mark Robertson said The idea behind the project was simple  to rediscover the very best of Scottish music from the finest musical talent spanning from the age of 70s rock through to 80s pop right up to todays international stars Everyone has strong opinions about this and we wanted to open it up to the public to decide he added BBC Radio Scotland presenter Vic Galloway who has been involved in the project said it had been great fun to look back at Scotlands musical heritage and take note of upandcoming Scottish acts   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  She had us at the hat toss Mary Richards was a modest Midwestern girl to be sure but she had style and she had spunk as her new boss Lou Grant pointed out the day she walked into the   newsroom in her white   boots a pleated miniskirt and those impeccable manners When she threw her tam in the air during the shows opening credits we knew she was thrilled to be single and on her own in the big city of Minneapolis But as the series unfolded and we watched Mary Tyler Moores most famous character dress for work in the uniform of career women all over the country     the clingy knit dresses the matching   pantsuits the Evan Picone separates     she showed us her heart was in that newsroom Ms Moore died on Wednesday in Greenwich Conn  Read Mary Tyler Moores obituary  5 great episodes to stream  There was a cultural sweet spot in the 1970s as the old social mores unraveled along with the sweater girl and women flexed new muscles as working women divorced women women commited to the single life newly conscious women     to use the parlance of the   feminist playbook     and fashion reflected the fluidity of that time As women were reinventing themselves fashion helped them along Clothing even in the office was colorful and personal those jersey dresses and knit pantsuits moved with the body And they were womanly Marys inherent authority     that moral compass     was never compromised by the fact that she dressed in the basic idiom of her gender By the next decade that freedom would be snuffed out and working girls would ape the rigid suits of their male competitors but thats another story And like all working women she wore the same outfit more than once and so her wardrobe became as familiar as our own Her predecessor Ann Marie of That Girl played by Marlo Thomas was our first television singleton but paired from the   with her boyfriend Donald She made her debut in the 1960s a period that for women on the small screen was still the dark ages Mary Richards had boyfriends but they were ancillary to her real life which played out at work Looking back at both shows the clothing displayed the maturation or the evolution of the female television avatar Ann Marie dressed almost like a child in the shows early episodes in the cartoonish youthquake fashions of Mary Quant and others which Ms Thomas brought with her from London The bunny hat notwithstanding Mary Richards looked like a    The Mary Tyler Moore Show always embraced the real world and as it unfurled that world grew a little darker as did Mary Richards clothes In the final episode the newsroom is under assault Ratings are low and Mary and the gang are fired But Mary is armored Clad in a navy blue jumpsuit like a fighter pilot her hair cropped to her shoulders she is strong enough to say goodbye and turn out those lights   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Celebrities get to stay in jungleAll four contestants still remain in Im A Celebrity  Get Me Out Of Here as no evictions were made on the television show on SaturdayContestants Paul Burrell Joe Pasquale Janet StreetPorter and Fran Cosgrave were told by hosts Ant and Dec Natalie Appletons decision to quit the show last Monday had given them all a stay of execution the group were told Model Sophie Anderton was the last person to be voted off the ITV1 show set in the Australian jungle The four remaining stars will do a joint Bushtucker Trial on SundayFormer All Saints singer Natalie Appleton31 walked out of the show after learning she would face a fifth socalled Bushtucker Trial The celebrities are chosen by the viewers to pass trials in order to win food for the rest of the camp Appleton had endured a torrid time during the programme including a wellpublicised row with Sophie Anderton And on 26 November singer Brian Harvey quit as a contestant after he had a blazing row with Janet StreetPorter   \n",
              "3  A few hours after her fathers news conference on Wednesday at Trump Tower Ivanka Trump posted a notice on her personal Facebook page officially announcing that she was taking a formal leave of absence from all management and operative responsibilities at her fashion brand and that she would be stepping down from her role at the Trump Organization She would she wrote be spending the next few months concentrating on settling her children into their new lives in Washington and exploring how she could determine the most impactful and appropriate ways for me to serve our country  This follows earlier decisions to separate her personal social media accounts from those of her brand Yet in one meaningful area Ms Trump and her brand are harder to divide That is her wardrobe After all the same day she announced she was separating Ivanka Trump the person from Ivanka Trump the brand The Daily Mail announced she had worn an Ivanka Trump coat to her fathers news conference Then it offered a    box and link In case you know anyone wanted to buy the garment That turned out not to be true     according to a spokesman for Ms Trump the coat was by Joseph Altuzarra     but the confusion around woman and product made for some uncomfortable optics and it raises the question What does it mean to separate individual from company where fashion is concerned On the one hand theres something ridiculous about suggesting that Ms Trump not wear whatever clothes are in her closet and as the founder of a fashion brand that bears her name presumably part of her job has been to promote said brand by wearing it     to in effect demonstrate her belief in her own products So she probably has a lot of such products within reach And its not her fault if some media outlet chooses to point out that she looks good and tells people how they too can look good On the other hand her brand is clearly built on her image Not just her name but her face and what she represents Its selling the promise that women who wear her clothes can get a piece of her gold dust     and now that this gold dust is visible in the corridors and news conferences of power that is only going to be more true Every time she is pictured in an Ivanka Trump outfit it is bound to give a boost to the Ivanka Trump brand Whether or not they are technically linked Its unclear whether Ms Trump would benefit from that financially as specifics about her monetary relationship with her brand were not included in her statement But even if she is selling her part of the company for a prominent member of the first family to be seen to be endorsing a brand with her own name on it is a complicated proposition And an endorsement is exactly what an appearance in an item of clothing has become This is a time like it or not of obsession with the wardrobe selections of anyone in the public eye especially women in the public eye their clothes are more interesting than mens after all And though she has repeatedly said that she will not take a formal role in the new administration Ms Trump is emerging as the female face of her fathers inner circle Simply consider the news conference where she was the only woman from the immediate family in attendance Theres a reason The Daily Mail did not get into the specifics of what her brothers wore She is smart enough to know that any time she steps out of her door someone is going to try to snap a picture and parse her clothes You can argue that Ms Trump is not an elected official and thus to demand that she recuse herself from all products associated with her name is unfair punishment You could say that if she wears for example an Alexander McQueen dress as she did on election night she is giving that brand a boost so why shouldnt she do the same for her own brand You can point out that there is precedent because she wore her own line numerous times during the campaign including to introduce her father at the Republican National Convention     but then the latter choice was not without controversy In part the resulting brouhaha was of course because her brand then promoted that appearance with its own get the look link as it famously did without her knowledge when she wore her   bracelet during her familys appearance on 60 Minutes  Presumably that wont happen any more But brands need personalities to succeed at whatever price point and those personalities derive most easily from well a person A scenario in which Ivanka Trump the brand removes Ms Trump utterly from its identity is hard to imagine Though to be fair the brands website is adorned with images and line drawings of many different kinds of women and not with Ms Trump so it may be possible Either way this is another illustration of the multiple complicated issues that are going to arise with a member of the first family who also had designs on being a fashion brand Theres really no playbook for this as the Ivanka team     figuring it out as it goes along     is quick to remind In which case the clothes question should be the next piece of the puzzle to be solved   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Oscars race enters final furlongThe race for the Oscars entered its final stages as the deadline for voters to choose their winners passedThe 5808 Academy voters had until Tuesday afternoon to return their ballots  any late submissions will not be included in the count The next five days will be spent counting the voting forms and preparing the winners envelopes Best actor nominee Leonardo DiCaprio is to present a statuette for the first time at the LA ceremony on SundayThe 30yearold actor who is nominated for playing Howard Hughes in The Aviator will join other hopefuls such as costar Cate Blanchett Natalie Portman and Kate Winslet as Oscar presenters The only people who will know the Oscar winners before they are revealed at the ceremony will be the auditors who are in charge of looking after the ballot countAfter collating the results they are responsible for sealing the results in the famous golden envelopes which will be revealed by a host of celebrity presenters at the ceremony Former Academy Award winners Gwyneth Paltrow Dustin Hoffman and Halle Berry will also present prizes The event at the Kodak Theatre will be attended by 3300 people including some of the bestknown names in film and organisers say they expect it will be watched on television by one billion people around the world One current concern is the torrential rain which has lashed Los Angeles for the past week flooding suburbs and causing mudslides It is hoped the forecast for Sunday for cool weather but no rain will prove accurate The last time it rained on Oscars night was in the midtolate 1980s said Oscars communications director John Pavlik We have had rain up until the day before the show many times but for some reason the Oscar gods always shine on Sunday and we hope they will do so again this year he added   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Actual Summary  \\\n",
              "0                                                                                                                                                                                                                                                                              Belle  Sebastian have been named the best Scottish band of all time after a three monthlong public pollScottish magazine The List recently compiled a list of the top 50 Scottish bands of all time but left the final decision to the publicScottish bands from earlier musical eras also made it into the final list including 1970s tartan boy band the Bay City Rollers and goth favourites the Jesus and Mary ChainScottishbased band Snow Patrol who finished 14th in the vote and have been nominated for a pair of Brit Awards were among the performers who covered wellknown Scottish pop songs at the party on Wednesday nightBBC Radio Scotland presenter Vic Galloway who has been involved in the project said it had been great fun to look back at Scotlands musical heritage and take note of upandcoming Scottish acts   \n",
              "1                                                        But as the series unfolded and we watched Mary Tyler Moores most famous character dress for work in the uniform of career women all over the country  the clingy knit dresses the matching pantsuits the Evan Picone separates  she showed us her heart was in that newsroom\\n\\nMs Moore died on Wednesday in Greenwich Conn There was a cultural sweet spot in the 1970s as the old social mores unraveled and women flexed new muscles as working women divorced women women commited to the single life newly conscious women  to use the parlance of the feminist playbook  and fashion reflected the fluidity of that time\\n\\nMary Richards had boyfriends but they were ancillary to her real life which played out at work\\n\\nAnn Marie dressed almost like a child in the shows early episodes in the cartoonish youthquake fashions of Mary Quant and others which Ms Thomas brought with her from London\\n\\nThe Mary Tyler Moore Show always embraced the real world and as it unfurled that world grew a little darker as did Mary Richards clothes   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Former All Saints singer Natalie Appleton31 walked out of the show after learning she would face a fifth socalled Bushtucker TrialAll four contestants still remain in Im A Celebrity  Get Me Out Of Here as no evictions were made on the television show on SaturdayAnd on 26 November singer Brian Harvey quit as a contestant after he had a blazing row with Janet StreetPorterModel Sophie Anderton was the last person to be voted off the ITV1 show set in the Australian jungle   \n",
              "3  A few hours after her fathers news conference on Wednesday at Trump Tower Ivanka Trump posted a notice on her personal Facebook page officially announcing that she was taking a formal leave of absence from all management and operative responsibilities at her fashion brand and that she would be stepping down from her role at the Trump Organization\\n\\nAfter all the same day she announced she was separating Ivanka Trump the person from Ivanka Trump the brand The Daily Mail announced she had worn an Ivanka Trump coat to her fathers news conference\\n\\nOn the one hand theres something ridiculous about suggesting that Ms Trump not wear whatever clothes are in her closet and as the founder of a fashion brand that bears her name presumably part of her job has been to promote said brand by wearing it  to in effect demonstrate her belief in her own products\\n\\nEvery time she is pictured in an Ivanka Trump outfit it is bound to give a boost to the Ivanka Trump brand\\n\\nA scenario in which Ivanka Trump the brand removes Ms Trump utterly from its identity is hard to imagine   \n",
              "4                                                                                                                                                                                                                                                                                                                           The only people who will know the Oscar winners before they are revealed at the ceremony will be the auditors who are in charge of looking after the ballot countWe have had rain up until the day before the show many times but for some reason the Oscar gods always shine on Sunday and we hope they will do so again this year he addedBest actor nominee Leonardo DiCaprio is to present a statuette for the first time at the LA ceremony on SundayThe race for the Oscars entered its final stages as the deadline for voters to choose their winners passedIt is hoped the forecast for Sunday for cool weather but no rain will prove accurateThe 5808 Academy voters had until Tuesday afternoon to return their ballots  any late submissions will not be included in the count   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Predicted Summary  \\\n",
              "0                                                                                                                                                                                                                                                           If you recently picked up five Brit Award nominations ended up in 15th place while the Eurythmics on a high on a party in Glasgow where the result was announced (Belle named best Scottish bandBelle  Sebastian have been named the best “Best Scottish band of all time after a three monthlong public pollThe group beat Travis and Idlewild into second and third place on Wednesday nightHonie on the highest highest highest awarded highest highest on high highest ground on the ground on Wednesday Night Franz Ferdinand who recently picked a high high “You’ki’’s “If” or “E‘›”“If you’st on the top 50 performed   \n",
              "1                                                                                                                                                                                                                                          She’s wearing a white   boots a pleated miniskirt and those impeccable manners When she threw her tam in the air during the shows opening credits we knew she was thrilled to be single and on her own in the big city of Minneapolis But as the series unfolded and we watched Mary Tyler Moores most famous Midwestern girl to be sure but she had style and she had spunk as her new boss Lou Grant pointed out the day she walked into the    newsroom in her white iced   black   white  bikki   bkk on top of the highest ground on the ground with your highest pins on your current Mau Mau Maui wears on Wednesday in Greenwich Conn    \n",
              "2                                                                                                                                                                                                                                                                                                     ”“’›› on your Ter on “If’ on a Ter Ter on on Mau Mau Mau on on Ter Ter in Im A Celebrity  Get Me Out Of Here as no on the on the television show on Saturday on SaturdayContestants Paul Burrell Joe Pasquale Janet StreetPorter and Fran Cosgrave were told by hosts Ant and Dec Natalie Appletines by “On’ Ter” on the show last Monday had given them all a stay of execution the group were told Model Sophie Anderton was the last person to be voted off the ITV1 show on the Ter Terrace on the Australian Terrace Race on SundayFormer All Saints singer Natalie Appleton31   \n",
              "3  A few hours after her father news conference on Wednesday at Trump Tower Ivanka Trump posted a notice on her personal Facebook page officially announcing that she was taking a formal leave of absence from all management and operative responsibilities at her fashion brand and that she would be stepping down from her role at the Trump Organization She would she wrote be spending the next few months concentrating on settling her children into their new lives in Washington and exploring how she could determine the most impactful and appropriate ways for me to serve our country  This follows earlier decisions to separate her personal social media accounts from those of her brand Yet in one meaningful area Ms Trump and her brand are harder to divide That is her wardrobe After all the same day she announced she was separating Ivanka Trump the person   \n",
              "4                                                                                                                                                            The next five days will be spent counting the voting forms and preparing the winners envelopes Best actor nominee Leonardo DiCaprio is to present a statuette for the first time at the LA ceremony on SundayThe 30yearold actor who is nominated for playing Howard Hughes in The Aviator will join other hopefuls such as costar Cate Blanche on the race for the Oscars entered its final stages as the deadline for voters to choose their winners onThe 5808 Academy voters had until Tuesday afternoon to return their ballots  any late submissions will not be included in the count The next 5 days will are spent watching the voting “If you’re a current aimon’s you are responsible for watching the results in   \n",
              "\n",
              "   ROUGE-2 Precision  \n",
              "0           0.131387  \n",
              "1           0.113636  \n",
              "2           0.395062  \n",
              "3           0.370370  \n",
              "4           0.401460  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_articles, actual_summaries, predicted_summaries, rouge2_precision_scores = evaluate2(model, test_dataloader)\n",
        "\n",
        "# Create a dictionary with the extracted data\n",
        "data = {\n",
        "    'Article': test_articles,\n",
        "    'Actual Summary': actual_summaries,\n",
        "    'Predicted Summary': predicted_summaries,\n",
        "    'ROUGE-2 Precision': rouge2_precision_scores,\n",
        "}\n",
        "\n",
        "# Create a Pandas DataFrame from the dictionary\n",
        "results_rouge2_df = pd.DataFrame(data)\n",
        "\n",
        "results_rouge2_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2peOZZncTmAu"
      },
      "outputs": [],
      "source": [
        "results_rouge2_df.to_excel('results_rouge22.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtCbZJ0QXpOO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.save_pretrained(\"pre_train_sum_batch_4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "abc=\"Samantha Bee called out Mark Meadows, who was White House chief of staff under Donald Trump, after 2,319 of his text messages revealed how deep he and other key Republicans were involved in the plot to overturn the election and stop Joe Biden from becoming president. ??More than 2,000 text messages!?? Bee said on ??Full Frontal?? on Thursday night. ??This proves definitively that Mark Meadows is a gossipy little bitch.?? The messages included Fox News host Sean Hannity taking orders from the White House on how to help with voter turnout on Election Day, Sen. Mike Lee (R-Utah) pleading for talking points after the election and Rep. Marjorie Taylor Greene (R-Ga.) calling for ??Marshall?? law. ??Marshall??s Law, as everyone knows, is that no one should pay retail prices for quality yoga pants,?? Bee cracked. Bee also noted that Meadows still has more than 1,000 messages that he hasn??t turned over. ??Damn! Mark Meadows, you are messy,?? she said. ??Delete my number!??Bee urged the Jan. 6 committee to push forward with its investigation. ??If there??s one thing these texts prove it??s that it doesn??t matter to Republicans if they know for a fact that Joe Biden won the election,?? she said. ??What matters is these human bumper stickers are more than willing to use lies and a violent base to both take and keep power.?? And she warned that if they??re not held accountable, it??ll happen again:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = tokenizer.encode(abc, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_ids = model.generate(input_ids=input_ids, max_length=1024, num_beams=17, length_penalty=2.0, early_stopping=False)\n",
        "generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Samantha Bee called out Mark Meadows, who was White House chief of staff under Donald Trump, after 2,319 of his text messages revealed how deep he and other key Republicans were involved in the plot to overturn the election and stop Joe Biden from becoming president.?\\x80?More than 2,000 text messages!?\\x80” Bee said on?\\x83?Full Frontal?\\x80& on Thursday night.?\\u2000?This proves definitively that Mark Meadows is a gossipy little bitch.?\\x80?, Bee said. The messages included Fox News host Sean Hannity taking orders from the White House on how to help with voter turnout on Election Day, Sen. Mike Lee (R-Utah) pleading for talking points after the election, Rep. Marjorie Taylor, a member of the House Judiciary Committee, and Rep. David Cicilline, R-N.Y., calling for an investigation into Meadows’ alleged role in the conspiracy, according to Bee’s transcript of the Jan. 6 committee hearing, as well as a letter from Rep. Mark Meadows to Rep. Bob Goodlatte, D-Va., urging him to “delete my number.”?Bee urged Meadows to delete his number, which he hasn’t done, as everyone knows, is that no one should pay retail prices for quality yoga pants,?½�? Bee cracked. Bee also noted that Meadows still has more than 1,000 messages that he hasn?“?t turned over to the House Oversight and Government Reform Committee, which is looking into the allegations against him and his aides.? \\x80?Damn! I’m going to delete my number, you are not going to do anything about it,”” she said in a video posted to her Twitter account on Jan. 5. And she warned that if the committee is not held accountable:Bee urged the committee to push forward with its investigation into the “toxic” text messages:If there?\\x9c?s one thing these texts prove it?¶?n”t matter to Republicans if they know for a fact that Joe Biden won the election or that Hillary Clinton is running for president, or that is what matters is these human bumper stickers are proof that these people are more than willing to use lies and a violent base to both take and keep power.?\\x9d? And she urged that if they?\\x8d�?re not held liable, it?\\x81?ll happen again:'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    cleaned_text = text.translate(translator).lower()\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rouge_1_evaluation(reference, generated):\n",
        "    reference = clean_text(reference)\n",
        "    generated = clean_text(generated)\n",
        "\n",
        "    reference_tokens = reference.split()\n",
        "    generated_tokens = generated.split()\n",
        "\n",
        "    # Calculate ROUGE-1 recall\n",
        "    overlapping_tokens = set(reference_tokens) & set(generated_tokens)\n",
        "    recall = len(overlapping_tokens) / len(reference_tokens) if len(reference_tokens) > 0 else 0.0\n",
        "\n",
        "    return recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE-1 Recall: 0.6059322033898306\n"
          ]
        }
      ],
      "source": [
        "rouge_1_recall = rouge_1_evaluation(abc, generated_summary)\n",
        "print(f\"ROUGE-1 Recall: {rouge_1_recall}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rouge_2_evaluation(reference, generated):\n",
        "    reference = clean_text(reference)\n",
        "    generated = clean_text(generated)\n",
        "\n",
        "    reference_bigrams = list(zip(reference.split()[:-1], reference.split()[1:]))\n",
        "    generated_bigrams = list(zip(generated.split()[:-1], generated.split()[1:]))\n",
        "\n",
        "    # Calculate ROUGE-2 recall\n",
        "    overlapping_bigrams = set(reference_bigrams) & set(generated_bigrams)\n",
        "    recall = len(overlapping_bigrams) / len(reference_bigrams) if len(reference_bigrams) > 0 else 0.0\n",
        "\n",
        "    return recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE-2 Recall: 0.7489361702127659\n"
          ]
        }
      ],
      "source": [
        "rouge_2_recall = rouge_2_evaluation(abc, generated_summary)\n",
        "print(f\"ROUGE-2 Recall: {rouge_2_recall}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 768, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.from_pretrained(\"facebook/bart-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "abc = \"Superhero clichés: The 45-year-old actor and stand up comedian played an alien who came to Earth to protect his planet, becoming a Bollywood star to blend in. But despite high anticipation for the film, which was directed by Oscar winner Chloé Zhao, it received a relatively poor 47% rating on Rotten Tomatoes and achieved the lowest score of any Marvel Cinematic Universe film in audience survey Cinema Score. Empire said at the time of release: Chloé Zhao's entry into the superhero world is assured, ambitious and told on a dizzyingly cosmic scale - but even it can't escape the clichés of superhero storytelling. The Guardian's Peter Bradshaw wrote: There are some nice touches and an attractive new diversity worn lightly, but this is an underpowered and uncertain film. Nanjiani and his wife, Emily V Gordon, were Oscar nominees in 2018 for their romantic comedy The Big Sick, in which he starred alongside Zoe Kazan. He's one of many stars who have spoken out about dealing with bad reviews in film and TV. Melissa McCarthy said in an interview that she confronted a critic at the Toronto Film Festival who had previously criticised her for her appearance in 2014 film Tammy. Jennifer Lawrence said in Variety that she gets defensive after reading negative reviews of her work. You're so in the zone, you put your whole soul and body, you move to shoot a movie, and you then love it, obviously because you wouldn't be there if you didn't love it, and then people just destroy it, she explained.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = tokenizer.encode(\"summarize:\"+ abc, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_ids = model.generate(input_ids=input_ids, max_length=1024, num_beams=50, length_penalty=1.0, early_stopping=True)\n",
        "generated_summary = tokenizer.decode(summary_ids[1], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "generated_summary = tokenizer.decode(summary_ids[-1], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate2(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    test_articles = []\n",
        "    actual_summaries = []\n",
        "    predicted_summaries = []\n",
        "    rouge2_precision_scores = []\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge2'])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating Test\"):\n",
        "            inputs = batch[0].to(device)\n",
        "            attention_mask = (inputs != 0).float().to(device)\n",
        "            targets = batch[1].to(device)\n",
        "            outputs = model.generate(input_ids=inputs, attention_mask=attention_mask, max_length=512, num_beams=30, length_penalty=3.0, early_stopping=True)\n",
        "\n",
        "            for output, target, input_text in zip(outputs, targets, inputs):\n",
        "                # Calculate ROUGE-2 precision for each sample\n",
        "                output_text = tokenizer.decode(output, skip_special_tokens=True)\n",
        "                target_text = tokenizer.decode(target, skip_special_tokens=True)\n",
        "                rouge_scores = scorer.score(output_text, target_text)\n",
        "                rouge2_precision_scores.append(rouge_scores['rouge2'].precision)\n",
        "\n",
        "                # Append tokenized text, actual summaries, and predicted summaries\n",
        "                test_articles.append(tokenizer.decode(input_text, skip_special_tokens=True))\n",
        "                actual_summaries.append(target_text)\n",
        "                predicted_summaries.append(output_text)\n",
        "\n",
        "    return test_articles, actual_summaries, predicted_summaries, rouge2_precision_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Superhero clichés: The 45-year-old actor and stand up comedian played an alien who came to Earth to protect his planet, becoming a Bollywood star to blend in. But despite high anticipation for the film, which was directed by Oscar winner Chloé Zhao, it received a relatively poor 47% rating on Rotten Tomatoes and achieved the lowest score of any Marvel Cinematic Universe film in audience survey Cinema Score. Empire said at the time of release: Chloé Zhao's entry into the superhero world is assured, ambitious and told on a dizzyingly cosmic scale - but even it can't escape the clichés of superhero storytelling. The Guardian's Peter Bradshaw wrote: There are some nice touches and an attractive new diversity worn lightly, but this is an underpowered and uncertain film. Nanjiani and his wife, Emily V Gordon, were Oscar nominees in 2018 for their romantic comedy The Big Sick, in which he starred alongside Zoe Kazan. He's one of many stars who have spoken out about dealing with bad reviews in film and TV. Melissa McCarthy said in an interview that she confronted a critic at the Toronto Film Festival who had previously criticised her for her appearance in 2014 film Tammy. Jennifer Lawrence said in Variety that she gets defensive after reading negative reviews of her work. You're so in the zone, you put your whole soul and body, you move to shoot a movie, and you then love it, obviously because you wouldn't be there if you didn't love it, and then people just destroy it, she explained.\""
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = tokenizer(abc, return_tensors='pt', max_length=1024, truncation=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Summary: Superhero clichés: The 45-year-old actor and stand up comedian played an alien who came to Earth to protect his planet, becoming a Bollywood star to blend in. But despite high anticipation for the film, which was directed by Oscar winner Chloé Zhao, it received a relatively poor 47% rating on Rotten Tomatoes and achieved the lowest score of any Marvel Cinematic Universe film in audience survey Cinema Score. Empire said at the time of release: Chloek Zhao's entry into the superhero world is assured, ambitious and told on a dizzyingly cosmic scale - but even it can't escape the clichés of superhero storytelling. The Guardian's Peter Bradshaw wrote: There are some nice touches and an attractive new diversity worn lightly, but this is an underpowered and uncertain film. Nanjiani and his wife, Emily V Gordon, were Oscar nominees in 2018 for their romantic comedy The Big Sick, in which he starred alongside Zoe Kazan. He's one of many stars who have spoken out about dealing with bad reviews in film and TV. Melissa McCarthy said in an interview that she confronted a critic at the Toronto Film Festival who had previously criticised her for her appearance in 2014 film Tammy. Jennifer Lawrence said in Variety that she gets defensive after reading negative reviews of her work. You're so in the zone, you put your whole soul and body, you move to shoot a movie, and you then love it, obviously because you wouldn't be there if you didn't love it. And then people just destroy it, she explained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "# Define your article\n",
        "\n",
        "\n",
        "# Initialize BART tokenizer and model\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "\n",
        "# Tokenize the article\n",
        "inputs = tokenizer(abc, return_tensors='pt', max_length=1024, truncation=True)\n",
        "\n",
        "# Generate predictions\n",
        "outputs = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=512, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "predicted_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Predicted Summary:\", predicted_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Summary: Superhero clichés: The 45-year-old actor and stand up comedian played an alien who came to Earth to protect his planet, becoming a Bollywood star to blend in. But despite high anticipation for the film, which was directed by Oscar winner Chloé Zhao, it received a relatively poor 47% rating on Rotten Tomatoes and achieved the lowest score of any Marvel Cinematic Universe film in audience survey Cinema Score. Empire said at the time of release: Chloek Zhao's entry into the superhero world is assured, ambitious and told on a dizzyingly cosmic scale - but even it can't escape the clichés of superhero storytelling. The Guardian's Peter Bradshaw wrote: There are some nice touches and an attractive new diversity worn lightly, but this is an underpowered and uncertain film. Nanjiani and his wife, Emily V Gordon, were Oscar nominees in 2018 for their romantic comedy The Big Sick, in which he starred alongside Zoe Kazan. He's one of many stars who have spoken out about dealing with bad reviews in film and TV. Melissa McCarthy said in an interview that she confronted a critic at the Toronto Film Festival who had previously criticised her for her appearance in 2014 film Tammy. Jennifer Lawrence said in Variety that she gets defensive after reading negative reviews of her work. You're so in the zone, you put your whole soul and body, you move to shoot a movie, and you then love it, obviously because you wouldn't be there if you didn't love it. And then people just destroy it, she explained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "\n",
        "# Tokenize the article\n",
        "inputs = tokenizer(abc, return_tensors='pt', max_length=1024, truncation=True)\n",
        "\n",
        "# Generate predictions\n",
        "outputs = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=512, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "predicted_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Predicted Summary:\", predicted_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "066d6d7d10b54583a09cf7c08a874581": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a7f6e94dc9849fdb93000eb118d0dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1222626362114654838a3c800d5bf9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15685bf25d0847e38e24e8156098a35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18ec1f06b06b4030afdab4374dd6b669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea76bd4fd37485d9b7af68e433b7ea7",
            "placeholder": "​",
            "style": "IPY_MODEL_3bb4137ef6fd4ae3b97d495a0ab33fa6",
            "value": "tokenizer.json: 100%"
          }
        },
        "19b34c333da949debd9aa987bdedc50d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6160dacfbd49f28b51ddfec75a0dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1f5ffb197c4c6c892987fea34e9bba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20fcad0c61e14ca487ad3238a60f07c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2335e907a4454f1b84b9d49936409c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2456eaf7fb974b8088460839ff104c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066d6d7d10b54583a09cf7c08a874581",
            "placeholder": "​",
            "style": "IPY_MODEL_d2be5caa361d4ccca12b105fe3388250",
            "value": " 899k/899k [00:00&lt;00:00, 1.13MB/s]"
          }
        },
        "2b0369f1b7574da28d3505b0f1b620cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3026edeb81e944768aa8ab39e27add98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b37d3baad64a369ea196e8dab97e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab0550ed999444639bbf99eab300ed75",
            "max": 557709915,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2335e907a4454f1b84b9d49936409c9a",
            "value": 557709915
          }
        },
        "3aeafe3ba1914caca3ad151f34640579": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b3c4f98d34946e4b9027be887363bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1be25eb162442e1b13ea1355169d3f1",
            "placeholder": "​",
            "style": "IPY_MODEL_15685bf25d0847e38e24e8156098a35a",
            "value": " 456k/456k [00:00&lt;00:00, 767kB/s]"
          }
        },
        "3bb4137ef6fd4ae3b97d495a0ab33fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40362fbd63bd40fc974d134581f82b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9233e4395062499985570de3f2252afc",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7399d9e108dc493db406a113f58d9582",
            "value": 456318
          }
        },
        "47c8f5699c7a4fa78a8facb75c9dfadc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48cd6da2bbdf43549648c8989dadae51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8586cc1d2c3c4207a5ef78a64d3757c9",
              "IPY_MODEL_863dd204bb0d4d8095dc157110efcee7",
              "IPY_MODEL_fa8f13e901b14ed6aad026b70d6e6c49"
            ],
            "layout": "IPY_MODEL_19b34c333da949debd9aa987bdedc50d"
          }
        },
        "4fce92fdfbc942deb64fddf08d4c11c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ea76bd4fd37485d9b7af68e433b7ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7399d9e108dc493db406a113f58d9582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75be190f9fa44cd3b8e26c21dd30efa2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772a3268234e4ead97c020c9daf3b893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c6ff626069f48ca9ff6f78e93f609a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f2dbc10d6c5436494053d04e690c4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3026edeb81e944768aa8ab39e27add98",
            "placeholder": "​",
            "style": "IPY_MODEL_b6c8dfcf93844a75aeb248db1d6cf10e",
            "value": "merges.txt: 100%"
          }
        },
        "8477577de62f4c6c828a8c394867b119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aeafe3ba1914caca3ad151f34640579",
            "placeholder": "​",
            "style": "IPY_MODEL_f7ed2de5ee0842e8b4859433ee131ba3",
            "value": "vocab.json: 100%"
          }
        },
        "8586cc1d2c3c4207a5ef78a64d3757c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb84d598a07844ebbf703bde8f81aabb",
            "placeholder": "​",
            "style": "IPY_MODEL_8e73ccb4ad314ba884adbf21df95a491",
            "value": "config.json: 100%"
          }
        },
        "863dd204bb0d4d8095dc157110efcee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c8f5699c7a4fa78a8facb75c9dfadc",
            "max": 1716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fce92fdfbc942deb64fddf08d4c11c5",
            "value": 1716
          }
        },
        "88b8bc860c6b4e34bdc2794370cedc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a711996a086461eb137f6536d2bba8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b930e19be7748cd84d2a8bb2e59ce0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1f5ffb197c4c6c892987fea34e9bba",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c03be050658e4b5d88d997289682328f",
            "value": 1355863
          }
        },
        "8e73ccb4ad314ba884adbf21df95a491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9233e4395062499985570de3f2252afc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da5ad56ea184cc88485ad79e6f33920": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32737b2f01d45e8b4a02908abe8575a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a332f2e780de4b1385d97828de8cd28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f2dbc10d6c5436494053d04e690c4f4",
              "IPY_MODEL_40362fbd63bd40fc974d134581f82b3b",
              "IPY_MODEL_3b3c4f98d34946e4b9027be887363bc1"
            ],
            "layout": "IPY_MODEL_20fcad0c61e14ca487ad3238a60f07c9"
          }
        },
        "a399fb03b3a04061bdd950dc80e5a6da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92d3b0cd6d04dafb6b65c31161086a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a5a40069a54f1a8575ba9f133ef5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_772a3268234e4ead97c020c9daf3b893",
            "value": "model.safetensors: 100%"
          }
        },
        "ab0550ed999444639bbf99eab300ed75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9fcfa0729e488bacba856323929d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8477577de62f4c6c828a8c394867b119",
              "IPY_MODEL_c0c119eed0004c1789634e730a2f99d5",
              "IPY_MODEL_2456eaf7fb974b8088460839ff104c0e"
            ],
            "layout": "IPY_MODEL_75be190f9fa44cd3b8e26c21dd30efa2"
          }
        },
        "b64a383e0ffd40059caf47dd4baf09ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b0369f1b7574da28d3505b0f1b620cf",
            "placeholder": "​",
            "style": "IPY_MODEL_88b8bc860c6b4e34bdc2794370cedc16",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.36MB/s]"
          }
        },
        "b6c8dfcf93844a75aeb248db1d6cf10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c03be050658e4b5d88d997289682328f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0c119eed0004c1789634e730a2f99d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c6ff626069f48ca9ff6f78e93f609a6",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a7f6e94dc9849fdb93000eb118d0dec",
            "value": 898823
          }
        },
        "c1be25eb162442e1b13ea1355169d3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8415c323544486b979fb09ee707a2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a92d3b0cd6d04dafb6b65c31161086a1",
              "IPY_MODEL_30b37d3baad64a369ea196e8dab97e78",
              "IPY_MODEL_fa40d9863b34461ab4ad7486a3a5caf3"
            ],
            "layout": "IPY_MODEL_9da5ad56ea184cc88485ad79e6f33920"
          }
        },
        "d2be5caa361d4ccca12b105fe3388250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eedee2bbb01b4461814d784ee65baa05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18ec1f06b06b4030afdab4374dd6b669",
              "IPY_MODEL_8b930e19be7748cd84d2a8bb2e59ce0c",
              "IPY_MODEL_b64a383e0ffd40059caf47dd4baf09ef"
            ],
            "layout": "IPY_MODEL_a399fb03b3a04061bdd950dc80e5a6da"
          }
        },
        "f1a5a40069a54f1a8575ba9f133ef5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7ed2de5ee0842e8b4859433ee131ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa40d9863b34461ab4ad7486a3a5caf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a711996a086461eb137f6536d2bba8a",
            "placeholder": "​",
            "style": "IPY_MODEL_1b6160dacfbd49f28b51ddfec75a0dc0",
            "value": " 558M/558M [00:07&lt;00:00, 79.5MB/s]"
          }
        },
        "fa8f13e901b14ed6aad026b70d6e6c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1222626362114654838a3c800d5bf9e7",
            "placeholder": "​",
            "style": "IPY_MODEL_a32737b2f01d45e8b4a02908abe8575a",
            "value": " 1.72k/1.72k [00:00&lt;00:00, 37.3kB/s]"
          }
        },
        "fb84d598a07844ebbf703bde8f81aabb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
