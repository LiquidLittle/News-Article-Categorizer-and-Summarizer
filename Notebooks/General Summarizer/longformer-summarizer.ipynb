{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7500723,"sourceType":"datasetVersion","datasetId":4360585}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\nfrom datasets import Dataset, load_metric\nimport numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-30T22:36:15.847338Z","iopub.execute_input":"2024-01-30T22:36:15.847699Z","iopub.status.idle":"2024-01-30T22:36:34.128362Z","shell.execute_reply.started":"2024-01-30T22:36:15.847668Z","shell.execute_reply":"2024-01-30T22:36:34.127374Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-01-30 22:36:24.751598: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-01-30 22:36:24.751704: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-01-30 22:36:24.896390: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade datasets","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:35:46.711297Z","iopub.execute_input":"2024-01-30T22:35:46.711597Z","iopub.status.idle":"2024-01-30T22:36:01.787742Z","shell.execute_reply.started":"2024-01-30T22:35:46.711572Z","shell.execute_reply":"2024-01-30T22:36:01.786633Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting datasets\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nCollecting pyarrow-hotfix (from datasets)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.12.2\n    Uninstalling fsspec-2023.12.2:\n      Successfully uninstalled fsspec-2023.12.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.16.1 fsspec-2023.10.0 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/huffdata-undersampled4k/test_set.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:00.723620Z","iopub.execute_input":"2024-01-30T22:37:00.724317Z","iopub.status.idle":"2024-01-30T22:37:02.030200Z","shell.execute_reply.started":"2024-01-30T22:37:00.724286Z","shell.execute_reply":"2024-01-30T22:37:02.029233Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = df[[\"text\", 'Summaries']]","metadata":{"execution":{"iopub.status.busy":"2024-01-30T21:43:54.498871Z","iopub.execute_input":"2024-01-30T21:43:54.499267Z","iopub.status.idle":"2024-01-30T21:43:54.514926Z","shell.execute_reply.started":"2024-01-30T21:43:54.499235Z","shell.execute_reply":"2024-01-30T21:43:54.513558Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_words = df.Summaries.apply(lambda x: len(x.split()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(num_words[num_words > 500])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_input_length = 5580\nmax_output_length = 512\nbatch_size = 1","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:06.781309Z","iopub.execute_input":"2024-01-30T22:37:06.781676Z","iopub.status.idle":"2024-01-30T22:37:06.786150Z","shell.execute_reply.started":"2024-01-30T22:37:06.781646Z","shell.execute_reply":"2024-01-30T22:37:06.785172Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def process_data_to_model_inputs(batch):\n    # tokenize the inputs and labels\n    inputs = tokenizer(\n        batch[\"text\"],\n        padding='max_length',\n        truncation=True,\n        max_length=max_input_length,\n    )\n    outputs = tokenizer(\n        batch[\"Summaries\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_output_length,\n    )\n\n    batch[\"input_ids\"] = inputs.input_ids\n    batch[\"attention_mask\"] = inputs.attention_mask\n\n    # create 0 global_attention_mask lists\n    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n    ]\n\n    # since above lists are references, the following line changes the 0 index for all samples\n    batch[\"global_attention_mask\"][0][0] = 1\n    batch[\"labels\"] = outputs.input_ids\n\n    # We have to make sure that the PAD token is ignored\n    batch[\"labels\"] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n        for labels in batch[\"labels\"]\n    ]\n\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:08.960229Z","iopub.execute_input":"2024-01-30T22:37:08.961159Z","iopub.status.idle":"2024-01-30T22:37:08.969049Z","shell.execute_reply.started":"2024-01-30T22:37:08.961124Z","shell.execute_reply":"2024-01-30T22:37:08.968106Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:11.282678Z","iopub.execute_input":"2024-01-30T22:37:11.283031Z","iopub.status.idle":"2024-01-30T22:37:25.897324Z","shell.execute_reply.started":"2024-01-30T22:37:11.283003Z","shell.execute_reply":"2024-01-30T22:37:25.896124Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.24.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=66ae9fa966eecb4f9ba65ce034cfab0c4e5ca58b767f198778e4e835ea7de287\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"rouge = load_metric(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-01-30T23:19:52.466714Z","iopub.execute_input":"2024-01-30T23:19:52.467690Z","iopub.status.idle":"2024-01-30T23:19:53.437058Z","shell.execute_reply.started":"2024-01-30T23:19:52.467653Z","shell.execute_reply":"2024-01-30T23:19:53.435805Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/4132584981.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  rouge = load_metric(\"rouge\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2acee2320b6545569ae1b361b3d91f9b"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n\n    rouge_output = rouge.compute(\n        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n    )[\"rouge2\"].mid\n\n    return {\n        \"rouge2_precision\": round(rouge_output.precision, 4),\n        \"rouge2_recall\": round(rouge_output.recall, 4),\n        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n    }","metadata":{"execution":{"iopub.status.busy":"2024-01-30T23:19:55.075528Z","iopub.execute_input":"2024-01-30T23:19:55.075902Z","iopub.status.idle":"2024-01-30T23:19:55.084529Z","shell.execute_reply.started":"2024-01-30T23:19:55.075874Z","shell.execute_reply":"2024-01-30T23:19:55.083134Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"raw_data = Dataset.from_pandas(df)\nsplit_data = raw_data.train_test_split(test_size=0.75)\nsplit_data = split_data['train'].train_test_split(test_size = 0.1)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:25.922520Z","iopub.execute_input":"2024-01-30T22:37:25.922782Z","iopub.status.idle":"2024-01-30T22:37:26.196054Z","shell.execute_reply.started":"2024-01-30T22:37:25.922761Z","shell.execute_reply":"2024-01-30T22:37:26.195299Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:31.113057Z","iopub.execute_input":"2024-01-30T22:37:31.113442Z","iopub.status.idle":"2024-01-30T22:37:32.929018Z","shell.execute_reply.started":"2024-01-30T22:37:31.113411Z","shell.execute_reply":"2024-01-30T22:37:32.928233Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3ad16fe1de4ea3bbb0ef60bb940508"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97948f7863984a60b5745453235f1e01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d2c9ae88fa345aebede990b50e63bde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c920d798e7b54ef7b765f793d733673a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17c90ee3a1d14fa39586bc183e2b5f78"}},"metadata":{}}]},{"cell_type":"code","source":"led = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:34.050874Z","iopub.execute_input":"2024-01-30T22:37:34.051254Z","iopub.status.idle":"2024-01-30T22:37:37.768392Z","shell.execute_reply.started":"2024-01-30T22:37:34.051222Z","shell.execute_reply":"2024-01-30T22:37:37.767514Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/648M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a2f8efa6f148e8b3daa747818156fa"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3980e7d7f8ad41e69c309de2ddc29a55"}},"metadata":{}}]},{"cell_type":"code","source":"led.config.num_beams = 2\nled.config.max_length = 512\nled.config.min_length = 100\nled.config.length_penalty = 2.0\nled.config.early_stopping = True\nled.config.no_repeat_ngram_size = 3","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:39.315307Z","iopub.execute_input":"2024-01-30T22:37:39.315675Z","iopub.status.idle":"2024-01-30T22:37:39.322033Z","shell.execute_reply.started":"2024-01-30T22:37:39.315646Z","shell.execute_reply":"2024-01-30T22:37:39.321179Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_dataset = split_data['train'].map(\n    process_data_to_model_inputs,\n    batched=True,\n    batch_size=batch_size,\n    remove_columns=[\"text\", \"Summaries\"]\n)\n\ntrain_dataset.set_format(\n    type=\"torch\",\n    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n)\n\ntest_dataset = split_data['test'].map(\n    process_data_to_model_inputs,\n    batched=True,\n    batch_size=batch_size,\n    remove_columns=[\"text\", \"Summaries\"],\n)\n\ntest_dataset.set_format(\n    type=\"torch\",\n    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:41.297112Z","iopub.execute_input":"2024-01-30T22:37:41.297982Z","iopub.status.idle":"2024-01-30T22:37:54.891324Z","shell.execute_reply.started":"2024-01-30T22:37:41.297951Z","shell.execute_reply":"2024-01-30T22:37:54.890396Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1225 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b525152d7554a66add3013e86f95a04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/137 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c32f5593f80b478cbef02b6c826bb663"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    evaluation_strategy=\"epoch\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    fp16=True,\n    output_dir=\"led-v1\",\n    logging_steps=250,\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    gradient_accumulation_steps=4,\n    load_best_model_at_end=True,\n    num_train_epochs=3,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:37:56.849276Z","iopub.execute_input":"2024-01-30T22:37:56.849906Z","iopub.status.idle":"2024-01-30T22:37:56.883552Z","shell.execute_reply.started":"2024-01-30T22:37:56.849874Z","shell.execute_reply":"2024-01-30T22:37:56.882812Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=led,\n    tokenizer=tokenizer,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T22:38:00.006688Z","iopub.execute_input":"2024-01-30T22:38:00.007121Z","iopub.status.idle":"2024-01-30T22:38:01.170218Z","shell.execute_reply.started":"2024-01-30T22:38:00.007092Z","shell.execute_reply":"2024-01-30T22:38:01.169421Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T23:20:00.598683Z","iopub.execute_input":"2024-01-30T23:20:00.599366Z","iopub.status.idle":"2024-01-31T01:02:36.834200Z","shell.execute_reply.started":"2024-01-30T23:20:00.599330Z","shell.execute_reply":"2024-01-31T01:02:36.833174Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='918' max='918' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [918/918 1:42:30, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge2 Precision</th>\n      <th>Rouge2 Recall</th>\n      <th>Rouge2 Fmeasure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.240900</td>\n      <td>0.223211</td>\n      <td>0.573400</td>\n      <td>0.492400</td>\n      <td>0.521800</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.184100</td>\n      <td>0.208663</td>\n      <td>0.596600</td>\n      <td>0.546000</td>\n      <td>0.562700</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.131200</td>\n      <td>0.208519</td>\n      <td>0.615800</td>\n      <td>0.583600</td>\n      <td>0.592600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'min_length': 100, 'early_stopping': True, 'num_beams': 2, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'min_length': 100, 'early_stopping': True, 'num_beams': 2, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'min_length': 100, 'early_stopping': True, 'num_beams': 2, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nThere were missing keys in the checkpoint model loaded: ['led.encoder.embed_tokens.weight', 'led.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=918, training_loss=0.17205999619560824, metrics={'train_runtime': 6155.6316, 'train_samples_per_second': 0.597, 'train_steps_per_second': 0.149, 'total_flos': 1.433512113924096e+16, 'train_loss': 0.17205999619560824, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2024-01-31T03:52:15.380098Z","iopub.execute_input":"2024-01-31T03:52:15.381376Z","iopub.status.idle":"2024-01-31T03:52:46.560163Z","shell.execute_reply.started":"2024-01-31T03:52:15.381314Z","shell.execute_reply":"2024-01-31T03:52:46.558713Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-01-31 03:52:26.392217: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-01-31 03:52:26.392449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-01-31 03:52:26.570021: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}