{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7500723,"sourceType":"datasetVersion","datasetId":4360585}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\nfrom datasets import Dataset, load_metric\nimport numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-09T23:39:22.837661Z","iopub.execute_input":"2024-02-09T23:39:22.838631Z","iopub.status.idle":"2024-02-09T23:39:22.845253Z","shell.execute_reply.started":"2024-02-09T23:39:22.838584Z","shell.execute_reply":"2024-02-09T23:39:22.843915Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade datasets","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:22.892881Z","iopub.execute_input":"2024-02-09T23:39:22.893873Z","iopub.status.idle":"2024-02-09T23:39:36.835122Z","shell.execute_reply.started":"2024-02-09T23:39:22.893833Z","shell.execute_reply":"2024-02-09T23:39:36.833769Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.17.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/huffdata-undersampled4k/test_set.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:36.838574Z","iopub.execute_input":"2024-02-09T23:39:36.839070Z","iopub.status.idle":"2024-02-09T23:39:37.143160Z","shell.execute_reply.started":"2024-02-09T23:39:36.839021Z","shell.execute_reply":"2024-02-09T23:39:37.141756Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df = df[[\"text\", 'Summaries']]","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:37.145025Z","iopub.execute_input":"2024-02-09T23:39:37.145399Z","iopub.status.idle":"2024-02-09T23:39:37.153983Z","shell.execute_reply.started":"2024-02-09T23:39:37.145366Z","shell.execute_reply":"2024-02-09T23:39:37.152683Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:37.155593Z","iopub.execute_input":"2024-02-09T23:39:37.156110Z","iopub.status.idle":"2024-02-09T23:39:37.177745Z","shell.execute_reply.started":"2024-02-09T23:39:37.156069Z","shell.execute_reply":"2024-02-09T23:39:37.176459Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                   text  \\\n0     Budget to set scene for election..Gordon Brown...   \n1     Army chiefs in regiments decision..Military ch...   \n2     Howard denies split over ID cards..Michael How...   \n3     Observers to monitor UK election..Ministers wi...   \n4     Kilroy names election seat target..Ex-chat sho...   \n...                                                 ...   \n5444  HONG KONG  —   Hundreds of pilot whales that s...   \n5445  NICE, France  —     Rivère accepts the complim...   \n5446  FRANKFURT  —   Germans who never really warmed...   \n5447  Charles Oakley has strong feelings about compe...   \n5448  Hans Rosling, a Swedish doctor who transformed...   \n\n                                              Summaries  \n0     - Increase in the stamp duty threshold from £6...  \n1     \"They are very much not for the good and will ...  \n2     Michael Howard has denied his shadow cabinet w...  \n3     The report said individual registration should...  \n4     UKIP's leader, Roger Knapman, has said he is g...  \n...                                                 ...  \n5444  more than 500 rescuers tried frantically to se...  \n5445  Signing balotelli was not just a way to garner...  \n5446  Although there was no evidence of that the bun...  \n5447  He questioned why any n. b. a. free agent woul...  \n5448  There are so many who think that death keeps c...  \n\n[5449 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Summaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Budget to set scene for election..Gordon Brown...</td>\n      <td>- Increase in the stamp duty threshold from £6...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Army chiefs in regiments decision..Military ch...</td>\n      <td>\"They are very much not for the good and will ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Howard denies split over ID cards..Michael How...</td>\n      <td>Michael Howard has denied his shadow cabinet w...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Observers to monitor UK election..Ministers wi...</td>\n      <td>The report said individual registration should...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kilroy names election seat target..Ex-chat sho...</td>\n      <td>UKIP's leader, Roger Knapman, has said he is g...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5444</th>\n      <td>HONG KONG  —   Hundreds of pilot whales that s...</td>\n      <td>more than 500 rescuers tried frantically to se...</td>\n    </tr>\n    <tr>\n      <th>5445</th>\n      <td>NICE, France  —     Rivère accepts the complim...</td>\n      <td>Signing balotelli was not just a way to garner...</td>\n    </tr>\n    <tr>\n      <th>5446</th>\n      <td>FRANKFURT  —   Germans who never really warmed...</td>\n      <td>Although there was no evidence of that the bun...</td>\n    </tr>\n    <tr>\n      <th>5447</th>\n      <td>Charles Oakley has strong feelings about compe...</td>\n      <td>He questioned why any n. b. a. free agent woul...</td>\n    </tr>\n    <tr>\n      <th>5448</th>\n      <td>Hans Rosling, a Swedish doctor who transformed...</td>\n      <td>There are so many who think that death keeps c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5449 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"num_words = df.Summaries.apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:37.181731Z","iopub.execute_input":"2024-02-09T23:39:37.182206Z","iopub.status.idle":"2024-02-09T23:39:37.267340Z","shell.execute_reply.started":"2024-02-09T23:39:37.182152Z","shell.execute_reply":"2024-02-09T23:39:37.266132Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"len(num_words[num_words > 500])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:37.268786Z","iopub.execute_input":"2024-02-09T23:39:37.269101Z","iopub.status.idle":"2024-02-09T23:39:37.277774Z","shell.execute_reply.started":"2024-02-09T23:39:37.269074Z","shell.execute_reply":"2024-02-09T23:39:37.276758Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"34"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 5580\nmax_output_length = 512\nbatch_size = 1","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:37.279275Z","iopub.execute_input":"2024-02-09T23:39:37.279804Z","iopub.status.idle":"2024-02-09T23:39:37.286837Z","shell.execute_reply.started":"2024-02-09T23:39:37.279747Z","shell.execute_reply":"2024-02-09T23:39:37.285404Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def process_data_to_model_inputs(batch):\n    # tokenize the inputs and labels\n    inputs = tokenizer(\n        batch[\"text\"],\n        padding='max_length',\n        truncation=True,\n        max_length=max_input_length,\n    )\n    outputs = tokenizer(\n        batch[\"Summaries\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_output_length,\n    )\n\n    batch[\"input_ids\"] = inputs.input_ids\n    batch[\"attention_mask\"] = inputs.attention_mask\n\n    # create 0 global_attention_mask lists\n    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n    ]\n\n    # since above lists are references, the following line changes the 0 index for all samples\n    batch[\"global_attention_mask\"][0][0] = 1\n    batch[\"labels\"] = outputs.input_ids\n\n    # We have to make sure that the PAD token is ignored\n    batch[\"labels\"] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n        for labels in batch[\"labels\"]\n    ]\n\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:37.288289Z","iopub.execute_input":"2024-02-09T23:39:37.288731Z","iopub.status.idle":"2024-02-09T23:39:37.302212Z","shell.execute_reply.started":"2024-02-09T23:39:37.288695Z","shell.execute_reply":"2024-02-09T23:39:37.301234Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:37.304162Z","iopub.execute_input":"2024-02-09T23:39:37.304994Z","iopub.status.idle":"2024-02-09T23:39:51.161291Z","shell.execute_reply.started":"2024-02-09T23:39:37.304900Z","shell.execute_reply":"2024-02-09T23:39:51.159799Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.24.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"rouge = load_metric(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:51.163138Z","iopub.execute_input":"2024-02-09T23:39:51.163524Z","iopub.status.idle":"2024-02-09T23:39:51.439149Z","shell.execute_reply.started":"2024-02-09T23:39:51.163494Z","shell.execute_reply":"2024-02-09T23:39:51.437925Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n\n    rouge_output = rouge.compute(\n        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n    )[\"rouge2\"].mid\n\n    return {\n        \"rouge2_precision\": round(rouge_output.precision, 4),\n        \"rouge2_recall\": round(rouge_output.recall, 4),\n        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n    }","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:51.441092Z","iopub.execute_input":"2024-02-09T23:39:51.441943Z","iopub.status.idle":"2024-02-09T23:39:51.451298Z","shell.execute_reply.started":"2024-02-09T23:39:51.441902Z","shell.execute_reply":"2024-02-09T23:39:51.450359Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"raw_data = Dataset.from_pandas(df)\nsplit_data = raw_data.train_test_split(test_size=0.75)\nsplit_data = split_data['train'].train_test_split(test_size = 0.1)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:51.452863Z","iopub.execute_input":"2024-02-09T23:39:51.453216Z","iopub.status.idle":"2024-02-09T23:39:51.542785Z","shell.execute_reply.started":"2024-02-09T23:39:51.453183Z","shell.execute_reply":"2024-02-09T23:39:51.541655Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:51.544098Z","iopub.execute_input":"2024-02-09T23:39:51.544430Z","iopub.status.idle":"2024-02-09T23:39:51.822015Z","shell.execute_reply.started":"2024-02-09T23:39:51.544402Z","shell.execute_reply":"2024-02-09T23:39:51.820803Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"led = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:51.825779Z","iopub.execute_input":"2024-02-09T23:39:51.826128Z","iopub.status.idle":"2024-02-09T23:39:52.401199Z","shell.execute_reply.started":"2024-02-09T23:39:51.826098Z","shell.execute_reply":"2024-02-09T23:39:52.400084Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"led.config.num_beams = 2\nled.config.max_length = 512\nled.config.min_length = 100\nled.config.length_penalty = 2.0\nled.config.early_stopping = True\nled.config.no_repeat_ngram_size = 3","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:52.402816Z","iopub.execute_input":"2024-02-09T23:39:52.403271Z","iopub.status.idle":"2024-02-09T23:39:52.413116Z","shell.execute_reply.started":"2024-02-09T23:39:52.403229Z","shell.execute_reply":"2024-02-09T23:39:52.411976Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"train_dataset = split_data['train'].map(\n    process_data_to_model_inputs,\n    batched=True,\n    batch_size=batch_size,\n    remove_columns=[\"text\", \"Summaries\"]\n)\n\ntrain_dataset.set_format(\n    type=\"torch\",\n    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n)\n\ntest_dataset = split_data['test'].map(\n    process_data_to_model_inputs,\n    batched=True,\n    batch_size=batch_size,\n    remove_columns=[\"text\", \"Summaries\"],\n)\n\ntest_dataset.set_format(\n    type=\"torch\",\n    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:39:52.414316Z","iopub.execute_input":"2024-02-09T23:39:52.414616Z","iopub.status.idle":"2024-02-09T23:40:06.051694Z","shell.execute_reply.started":"2024-02-09T23:39:52.414591Z","shell.execute_reply":"2024-02-09T23:40:06.050458Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1225 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8df438203e47457ea8753b6827986c33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/137 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df4c40d6d0554eb3a3d3afb91102f9b4"}},"metadata":{}}]},{"cell_type":"code","source":"led","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:49:53.895106Z","iopub.execute_input":"2024-02-09T23:49:53.895535Z","iopub.status.idle":"2024-02-09T23:49:53.909722Z","shell.execute_reply.started":"2024-02-09T23:49:53.895499Z","shell.execute_reply":"2024-02-09T23:49:53.908290Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"LEDForConditionalGeneration(\n  (led): LEDModel(\n    (shared): Embedding(50265, 768, padding_idx=1)\n    (encoder): LEDEncoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): LEDLearnedPositionalEmbedding(16384, 768)\n      (layers): ModuleList(\n        (0-5): 6 x LEDEncoderLayer(\n          (self_attn): LEDEncoderAttention(\n            (longformer_self_attn): LEDEncoderSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (query_global): Linear(in_features=768, out_features=768, bias=True)\n              (key_global): Linear(in_features=768, out_features=768, bias=True)\n              (value_global): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (output): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): LEDDecoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): LEDLearnedPositionalEmbedding(1024, 768)\n      (layers): ModuleList(\n        (0-5): 6 x LEDDecoderLayer(\n          (self_attn): LEDDecoderAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): LEDDecoderAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"for param in led.led.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:51:13.912806Z","iopub.execute_input":"2024-02-09T23:51:13.913212Z","iopub.status.idle":"2024-02-09T23:51:13.925596Z","shell.execute_reply.started":"2024-02-09T23:51:13.913184Z","shell.execute_reply":"2024-02-09T23:51:13.924263Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for param in led.lm_head.parameters():\n    param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:51:28.569146Z","iopub.execute_input":"2024-02-09T23:51:28.570062Z","iopub.status.idle":"2024-02-09T23:51:28.576151Z","shell.execute_reply.started":"2024-02-09T23:51:28.570026Z","shell.execute_reply":"2024-02-09T23:51:28.575050Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"for name, param in led.named_parameters():\n     print(name, param.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:51:55.768729Z","iopub.execute_input":"2024-02-09T23:51:55.769640Z","iopub.status.idle":"2024-02-09T23:51:55.847484Z","shell.execute_reply.started":"2024-02-09T23:51:55.769584Z","shell.execute_reply":"2024-02-09T23:51:55.846325Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"led.shared.weight True\nled.encoder.embed_positions.weight False\nled.encoder.layers.0.self_attn.longformer_self_attn.query.weight False\nled.encoder.layers.0.self_attn.longformer_self_attn.query.bias False\nled.encoder.layers.0.self_attn.longformer_self_attn.key.weight False\nled.encoder.layers.0.self_attn.longformer_self_attn.key.bias False\nled.encoder.layers.0.self_attn.longformer_self_attn.value.weight False\nled.encoder.layers.0.self_attn.longformer_self_attn.value.bias False\nled.encoder.layers.0.self_attn.longformer_self_attn.query_global.weight False\nled.encoder.layers.0.self_attn.longformer_self_attn.query_global.bias False\nled.encoder.layers.0.self_attn.longformer_self_attn.key_global.weight False\nled.encoder.layers.0.self_attn.longformer_self_attn.key_global.bias False\nled.encoder.layers.0.self_attn.longformer_self_attn.value_global.weight False\nled.encoder.layers.0.self_attn.longformer_self_attn.value_global.bias False\nled.encoder.layers.0.self_attn.output.weight False\nled.encoder.layers.0.self_attn.output.bias False\nled.encoder.layers.0.self_attn_layer_norm.weight False\nled.encoder.layers.0.self_attn_layer_norm.bias False\nled.encoder.layers.0.fc1.weight False\nled.encoder.layers.0.fc1.bias False\nled.encoder.layers.0.fc2.weight False\nled.encoder.layers.0.fc2.bias False\nled.encoder.layers.0.final_layer_norm.weight False\nled.encoder.layers.0.final_layer_norm.bias False\nled.encoder.layers.1.self_attn.longformer_self_attn.query.weight False\nled.encoder.layers.1.self_attn.longformer_self_attn.query.bias False\nled.encoder.layers.1.self_attn.longformer_self_attn.key.weight False\nled.encoder.layers.1.self_attn.longformer_self_attn.key.bias False\nled.encoder.layers.1.self_attn.longformer_self_attn.value.weight False\nled.encoder.layers.1.self_attn.longformer_self_attn.value.bias False\nled.encoder.layers.1.self_attn.longformer_self_attn.query_global.weight False\nled.encoder.layers.1.self_attn.longformer_self_attn.query_global.bias False\nled.encoder.layers.1.self_attn.longformer_self_attn.key_global.weight False\nled.encoder.layers.1.self_attn.longformer_self_attn.key_global.bias False\nled.encoder.layers.1.self_attn.longformer_self_attn.value_global.weight False\nled.encoder.layers.1.self_attn.longformer_self_attn.value_global.bias False\nled.encoder.layers.1.self_attn.output.weight False\nled.encoder.layers.1.self_attn.output.bias False\nled.encoder.layers.1.self_attn_layer_norm.weight False\nled.encoder.layers.1.self_attn_layer_norm.bias False\nled.encoder.layers.1.fc1.weight False\nled.encoder.layers.1.fc1.bias False\nled.encoder.layers.1.fc2.weight False\nled.encoder.layers.1.fc2.bias False\nled.encoder.layers.1.final_layer_norm.weight False\nled.encoder.layers.1.final_layer_norm.bias False\nled.encoder.layers.2.self_attn.longformer_self_attn.query.weight False\nled.encoder.layers.2.self_attn.longformer_self_attn.query.bias False\nled.encoder.layers.2.self_attn.longformer_self_attn.key.weight False\nled.encoder.layers.2.self_attn.longformer_self_attn.key.bias False\nled.encoder.layers.2.self_attn.longformer_self_attn.value.weight False\nled.encoder.layers.2.self_attn.longformer_self_attn.value.bias False\nled.encoder.layers.2.self_attn.longformer_self_attn.query_global.weight False\nled.encoder.layers.2.self_attn.longformer_self_attn.query_global.bias False\nled.encoder.layers.2.self_attn.longformer_self_attn.key_global.weight False\nled.encoder.layers.2.self_attn.longformer_self_attn.key_global.bias False\nled.encoder.layers.2.self_attn.longformer_self_attn.value_global.weight False\nled.encoder.layers.2.self_attn.longformer_self_attn.value_global.bias False\nled.encoder.layers.2.self_attn.output.weight False\nled.encoder.layers.2.self_attn.output.bias False\nled.encoder.layers.2.self_attn_layer_norm.weight False\nled.encoder.layers.2.self_attn_layer_norm.bias False\nled.encoder.layers.2.fc1.weight False\nled.encoder.layers.2.fc1.bias False\nled.encoder.layers.2.fc2.weight False\nled.encoder.layers.2.fc2.bias False\nled.encoder.layers.2.final_layer_norm.weight False\nled.encoder.layers.2.final_layer_norm.bias False\nled.encoder.layers.3.self_attn.longformer_self_attn.query.weight False\nled.encoder.layers.3.self_attn.longformer_self_attn.query.bias False\nled.encoder.layers.3.self_attn.longformer_self_attn.key.weight False\nled.encoder.layers.3.self_attn.longformer_self_attn.key.bias False\nled.encoder.layers.3.self_attn.longformer_self_attn.value.weight False\nled.encoder.layers.3.self_attn.longformer_self_attn.value.bias False\nled.encoder.layers.3.self_attn.longformer_self_attn.query_global.weight False\nled.encoder.layers.3.self_attn.longformer_self_attn.query_global.bias False\nled.encoder.layers.3.self_attn.longformer_self_attn.key_global.weight False\nled.encoder.layers.3.self_attn.longformer_self_attn.key_global.bias False\nled.encoder.layers.3.self_attn.longformer_self_attn.value_global.weight False\nled.encoder.layers.3.self_attn.longformer_self_attn.value_global.bias False\nled.encoder.layers.3.self_attn.output.weight False\nled.encoder.layers.3.self_attn.output.bias False\nled.encoder.layers.3.self_attn_layer_norm.weight False\nled.encoder.layers.3.self_attn_layer_norm.bias False\nled.encoder.layers.3.fc1.weight False\nled.encoder.layers.3.fc1.bias False\nled.encoder.layers.3.fc2.weight False\nled.encoder.layers.3.fc2.bias False\nled.encoder.layers.3.final_layer_norm.weight False\nled.encoder.layers.3.final_layer_norm.bias False\nled.encoder.layers.4.self_attn.longformer_self_attn.query.weight False\nled.encoder.layers.4.self_attn.longformer_self_attn.query.bias False\nled.encoder.layers.4.self_attn.longformer_self_attn.key.weight False\nled.encoder.layers.4.self_attn.longformer_self_attn.key.bias False\nled.encoder.layers.4.self_attn.longformer_self_attn.value.weight False\nled.encoder.layers.4.self_attn.longformer_self_attn.value.bias False\nled.encoder.layers.4.self_attn.longformer_self_attn.query_global.weight False\nled.encoder.layers.4.self_attn.longformer_self_attn.query_global.bias False\nled.encoder.layers.4.self_attn.longformer_self_attn.key_global.weight False\nled.encoder.layers.4.self_attn.longformer_self_attn.key_global.bias False\nled.encoder.layers.4.self_attn.longformer_self_attn.value_global.weight False\nled.encoder.layers.4.self_attn.longformer_self_attn.value_global.bias False\nled.encoder.layers.4.self_attn.output.weight False\nled.encoder.layers.4.self_attn.output.bias False\nled.encoder.layers.4.self_attn_layer_norm.weight False\nled.encoder.layers.4.self_attn_layer_norm.bias False\nled.encoder.layers.4.fc1.weight False\nled.encoder.layers.4.fc1.bias False\nled.encoder.layers.4.fc2.weight False\nled.encoder.layers.4.fc2.bias False\nled.encoder.layers.4.final_layer_norm.weight False\nled.encoder.layers.4.final_layer_norm.bias False\nled.encoder.layers.5.self_attn.longformer_self_attn.query.weight False\nled.encoder.layers.5.self_attn.longformer_self_attn.query.bias False\nled.encoder.layers.5.self_attn.longformer_self_attn.key.weight False\nled.encoder.layers.5.self_attn.longformer_self_attn.key.bias False\nled.encoder.layers.5.self_attn.longformer_self_attn.value.weight False\nled.encoder.layers.5.self_attn.longformer_self_attn.value.bias False\nled.encoder.layers.5.self_attn.longformer_self_attn.query_global.weight False\nled.encoder.layers.5.self_attn.longformer_self_attn.query_global.bias False\nled.encoder.layers.5.self_attn.longformer_self_attn.key_global.weight False\nled.encoder.layers.5.self_attn.longformer_self_attn.key_global.bias False\nled.encoder.layers.5.self_attn.longformer_self_attn.value_global.weight False\nled.encoder.layers.5.self_attn.longformer_self_attn.value_global.bias False\nled.encoder.layers.5.self_attn.output.weight False\nled.encoder.layers.5.self_attn.output.bias False\nled.encoder.layers.5.self_attn_layer_norm.weight False\nled.encoder.layers.5.self_attn_layer_norm.bias False\nled.encoder.layers.5.fc1.weight False\nled.encoder.layers.5.fc1.bias False\nled.encoder.layers.5.fc2.weight False\nled.encoder.layers.5.fc2.bias False\nled.encoder.layers.5.final_layer_norm.weight False\nled.encoder.layers.5.final_layer_norm.bias False\nled.encoder.layernorm_embedding.weight False\nled.encoder.layernorm_embedding.bias False\nled.decoder.embed_positions.weight False\nled.decoder.layers.0.self_attn.k_proj.weight False\nled.decoder.layers.0.self_attn.k_proj.bias False\nled.decoder.layers.0.self_attn.v_proj.weight False\nled.decoder.layers.0.self_attn.v_proj.bias False\nled.decoder.layers.0.self_attn.q_proj.weight False\nled.decoder.layers.0.self_attn.q_proj.bias False\nled.decoder.layers.0.self_attn.out_proj.weight False\nled.decoder.layers.0.self_attn.out_proj.bias False\nled.decoder.layers.0.self_attn_layer_norm.weight False\nled.decoder.layers.0.self_attn_layer_norm.bias False\nled.decoder.layers.0.encoder_attn.k_proj.weight False\nled.decoder.layers.0.encoder_attn.k_proj.bias False\nled.decoder.layers.0.encoder_attn.v_proj.weight False\nled.decoder.layers.0.encoder_attn.v_proj.bias False\nled.decoder.layers.0.encoder_attn.q_proj.weight False\nled.decoder.layers.0.encoder_attn.q_proj.bias False\nled.decoder.layers.0.encoder_attn.out_proj.weight False\nled.decoder.layers.0.encoder_attn.out_proj.bias False\nled.decoder.layers.0.encoder_attn_layer_norm.weight False\nled.decoder.layers.0.encoder_attn_layer_norm.bias False\nled.decoder.layers.0.fc1.weight False\nled.decoder.layers.0.fc1.bias False\nled.decoder.layers.0.fc2.weight False\nled.decoder.layers.0.fc2.bias False\nled.decoder.layers.0.final_layer_norm.weight False\nled.decoder.layers.0.final_layer_norm.bias False\nled.decoder.layers.1.self_attn.k_proj.weight False\nled.decoder.layers.1.self_attn.k_proj.bias False\nled.decoder.layers.1.self_attn.v_proj.weight False\nled.decoder.layers.1.self_attn.v_proj.bias False\nled.decoder.layers.1.self_attn.q_proj.weight False\nled.decoder.layers.1.self_attn.q_proj.bias False\nled.decoder.layers.1.self_attn.out_proj.weight False\nled.decoder.layers.1.self_attn.out_proj.bias False\nled.decoder.layers.1.self_attn_layer_norm.weight False\nled.decoder.layers.1.self_attn_layer_norm.bias False\nled.decoder.layers.1.encoder_attn.k_proj.weight False\nled.decoder.layers.1.encoder_attn.k_proj.bias False\nled.decoder.layers.1.encoder_attn.v_proj.weight False\nled.decoder.layers.1.encoder_attn.v_proj.bias False\nled.decoder.layers.1.encoder_attn.q_proj.weight False\nled.decoder.layers.1.encoder_attn.q_proj.bias False\nled.decoder.layers.1.encoder_attn.out_proj.weight False\nled.decoder.layers.1.encoder_attn.out_proj.bias False\nled.decoder.layers.1.encoder_attn_layer_norm.weight False\nled.decoder.layers.1.encoder_attn_layer_norm.bias False\nled.decoder.layers.1.fc1.weight False\nled.decoder.layers.1.fc1.bias False\nled.decoder.layers.1.fc2.weight False\nled.decoder.layers.1.fc2.bias False\nled.decoder.layers.1.final_layer_norm.weight False\nled.decoder.layers.1.final_layer_norm.bias False\nled.decoder.layers.2.self_attn.k_proj.weight False\nled.decoder.layers.2.self_attn.k_proj.bias False\nled.decoder.layers.2.self_attn.v_proj.weight False\nled.decoder.layers.2.self_attn.v_proj.bias False\nled.decoder.layers.2.self_attn.q_proj.weight False\nled.decoder.layers.2.self_attn.q_proj.bias False\nled.decoder.layers.2.self_attn.out_proj.weight False\nled.decoder.layers.2.self_attn.out_proj.bias False\nled.decoder.layers.2.self_attn_layer_norm.weight False\nled.decoder.layers.2.self_attn_layer_norm.bias False\nled.decoder.layers.2.encoder_attn.k_proj.weight False\nled.decoder.layers.2.encoder_attn.k_proj.bias False\nled.decoder.layers.2.encoder_attn.v_proj.weight False\nled.decoder.layers.2.encoder_attn.v_proj.bias False\nled.decoder.layers.2.encoder_attn.q_proj.weight False\nled.decoder.layers.2.encoder_attn.q_proj.bias False\nled.decoder.layers.2.encoder_attn.out_proj.weight False\nled.decoder.layers.2.encoder_attn.out_proj.bias False\nled.decoder.layers.2.encoder_attn_layer_norm.weight False\nled.decoder.layers.2.encoder_attn_layer_norm.bias False\nled.decoder.layers.2.fc1.weight False\nled.decoder.layers.2.fc1.bias False\nled.decoder.layers.2.fc2.weight False\nled.decoder.layers.2.fc2.bias False\nled.decoder.layers.2.final_layer_norm.weight False\nled.decoder.layers.2.final_layer_norm.bias False\nled.decoder.layers.3.self_attn.k_proj.weight False\nled.decoder.layers.3.self_attn.k_proj.bias False\nled.decoder.layers.3.self_attn.v_proj.weight False\nled.decoder.layers.3.self_attn.v_proj.bias False\nled.decoder.layers.3.self_attn.q_proj.weight False\nled.decoder.layers.3.self_attn.q_proj.bias False\nled.decoder.layers.3.self_attn.out_proj.weight False\nled.decoder.layers.3.self_attn.out_proj.bias False\nled.decoder.layers.3.self_attn_layer_norm.weight False\nled.decoder.layers.3.self_attn_layer_norm.bias False\nled.decoder.layers.3.encoder_attn.k_proj.weight False\nled.decoder.layers.3.encoder_attn.k_proj.bias False\nled.decoder.layers.3.encoder_attn.v_proj.weight False\nled.decoder.layers.3.encoder_attn.v_proj.bias False\nled.decoder.layers.3.encoder_attn.q_proj.weight False\nled.decoder.layers.3.encoder_attn.q_proj.bias False\nled.decoder.layers.3.encoder_attn.out_proj.weight False\nled.decoder.layers.3.encoder_attn.out_proj.bias False\nled.decoder.layers.3.encoder_attn_layer_norm.weight False\nled.decoder.layers.3.encoder_attn_layer_norm.bias False\nled.decoder.layers.3.fc1.weight False\nled.decoder.layers.3.fc1.bias False\nled.decoder.layers.3.fc2.weight False\nled.decoder.layers.3.fc2.bias False\nled.decoder.layers.3.final_layer_norm.weight False\nled.decoder.layers.3.final_layer_norm.bias False\nled.decoder.layers.4.self_attn.k_proj.weight False\nled.decoder.layers.4.self_attn.k_proj.bias False\nled.decoder.layers.4.self_attn.v_proj.weight False\nled.decoder.layers.4.self_attn.v_proj.bias False\nled.decoder.layers.4.self_attn.q_proj.weight False\nled.decoder.layers.4.self_attn.q_proj.bias False\nled.decoder.layers.4.self_attn.out_proj.weight False\nled.decoder.layers.4.self_attn.out_proj.bias False\nled.decoder.layers.4.self_attn_layer_norm.weight False\nled.decoder.layers.4.self_attn_layer_norm.bias False\nled.decoder.layers.4.encoder_attn.k_proj.weight False\nled.decoder.layers.4.encoder_attn.k_proj.bias False\nled.decoder.layers.4.encoder_attn.v_proj.weight False\nled.decoder.layers.4.encoder_attn.v_proj.bias False\nled.decoder.layers.4.encoder_attn.q_proj.weight False\nled.decoder.layers.4.encoder_attn.q_proj.bias False\nled.decoder.layers.4.encoder_attn.out_proj.weight False\nled.decoder.layers.4.encoder_attn.out_proj.bias False\nled.decoder.layers.4.encoder_attn_layer_norm.weight False\nled.decoder.layers.4.encoder_attn_layer_norm.bias False\nled.decoder.layers.4.fc1.weight False\nled.decoder.layers.4.fc1.bias False\nled.decoder.layers.4.fc2.weight False\nled.decoder.layers.4.fc2.bias False\nled.decoder.layers.4.final_layer_norm.weight False\nled.decoder.layers.4.final_layer_norm.bias False\nled.decoder.layers.5.self_attn.k_proj.weight False\nled.decoder.layers.5.self_attn.k_proj.bias False\nled.decoder.layers.5.self_attn.v_proj.weight False\nled.decoder.layers.5.self_attn.v_proj.bias False\nled.decoder.layers.5.self_attn.q_proj.weight False\nled.decoder.layers.5.self_attn.q_proj.bias False\nled.decoder.layers.5.self_attn.out_proj.weight False\nled.decoder.layers.5.self_attn.out_proj.bias False\nled.decoder.layers.5.self_attn_layer_norm.weight False\nled.decoder.layers.5.self_attn_layer_norm.bias False\nled.decoder.layers.5.encoder_attn.k_proj.weight False\nled.decoder.layers.5.encoder_attn.k_proj.bias False\nled.decoder.layers.5.encoder_attn.v_proj.weight False\nled.decoder.layers.5.encoder_attn.v_proj.bias False\nled.decoder.layers.5.encoder_attn.q_proj.weight False\nled.decoder.layers.5.encoder_attn.q_proj.bias False\nled.decoder.layers.5.encoder_attn.out_proj.weight False\nled.decoder.layers.5.encoder_attn.out_proj.bias False\nled.decoder.layers.5.encoder_attn_layer_norm.weight False\nled.decoder.layers.5.encoder_attn_layer_norm.bias False\nled.decoder.layers.5.fc1.weight False\nled.decoder.layers.5.fc1.bias False\nled.decoder.layers.5.fc2.weight False\nled.decoder.layers.5.fc2.bias False\nled.decoder.layers.5.final_layer_norm.weight False\nled.decoder.layers.5.final_layer_norm.bias False\nled.decoder.layernorm_embedding.weight False\nled.decoder.layernorm_embedding.bias False\n","output_type":"stream"}]},{"cell_type":"code","source":"# led was built on old code, so it still uses np.object which has already depreceated. We manually set it here to avoid any errors\nnp.object = object","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:48:30.758938Z","iopub.execute_input":"2024-02-09T23:48:30.759760Z","iopub.status.idle":"2024-02-09T23:48:30.766827Z","shell.execute_reply.started":"2024-02-09T23:48:30.759721Z","shell.execute_reply":"2024-02-09T23:48:30.764838Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    evaluation_strategy=\"epoch\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    fp16=True,\n    output_dir=\"led-v1\",\n    logging_steps=250,\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    gradient_accumulation_steps=4,\n    load_best_model_at_end=True,\n    num_train_epochs=3,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:52:20.087590Z","iopub.execute_input":"2024-02-09T23:52:20.087984Z","iopub.status.idle":"2024-02-09T23:52:20.100463Z","shell.execute_reply.started":"2024-02-09T23:52:20.087938Z","shell.execute_reply":"2024-02-09T23:52:20.098453Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=led,\n    tokenizer=tokenizer,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:52:21.576882Z","iopub.execute_input":"2024-02-09T23:52:21.577293Z","iopub.status.idle":"2024-02-09T23:52:21.597813Z","shell.execute_reply.started":"2024-02-09T23:52:21.577262Z","shell.execute_reply":"2024-02-09T23:52:21.596588Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T23:52:23.329610Z","iopub.execute_input":"2024-02-09T23:52:23.330333Z","iopub.status.idle":"2024-02-10T01:39:09.947862Z","shell.execute_reply.started":"2024-02-09T23:52:23.330297Z","shell.execute_reply":"2024-02-10T01:39:09.946820Z"},"trusted":true},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='918' max='918' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [918/918 1:46:41, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge2 Precision</th>\n      <th>Rouge2 Recall</th>\n      <th>Rouge2 Fmeasure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.966000</td>\n      <td>0.902945</td>\n      <td>0.340900</td>\n      <td>0.585300</td>\n      <td>0.402400</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.837700</td>\n      <td>0.837789</td>\n      <td>0.385200</td>\n      <td>0.463500</td>\n      <td>0.382500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.787600</td>\n      <td>0.820543</td>\n      <td>0.405000</td>\n      <td>0.449100</td>\n      <td>0.388500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1290: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'min_length': 100, 'early_stopping': True, 'num_beams': 2, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nCheckpoint destination directory led-v1/checkpoint-612 already exists and is non-empty.Saving will proceed but saved results may be invalid.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'min_length': 100, 'early_stopping': True, 'num_beams': 2, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'min_length': 100, 'early_stopping': True, 'num_beams': 2, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\nThere were missing keys in the checkpoint model loaded: ['led.encoder.embed_tokens.weight', 'led.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=918, training_loss=0.8422524778411798, metrics={'train_runtime': 6406.0724, 'train_samples_per_second': 0.574, 'train_steps_per_second': 0.143, 'total_flos': 1.350745825591296e+16, 'train_loss': 0.8422524778411798, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2024-01-31T03:52:15.380098Z","iopub.execute_input":"2024-01-31T03:52:15.381376Z","iopub.status.idle":"2024-01-31T03:52:46.560163Z","shell.execute_reply.started":"2024-01-31T03:52:15.381314Z","shell.execute_reply":"2024-01-31T03:52:46.558713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}